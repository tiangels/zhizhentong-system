"""
RAGç³»ç»ŸAPIæ¥å£
æä¾›æ ‡å‡†åŒ–çš„REST APIæ¥å£ï¼Œä¾›å‰ç«¯å’Œå…¶ä»–æœåŠ¡è°ƒç”¨
"""

import os
import json
import logging
import asyncio
from typing import List, Dict, Any, Optional
from datetime import datetime
from pathlib import Path

from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel, Field
import uvicorn
import asyncio

# å¯¼å…¥RAGæ ¸å¿ƒæ¨¡å—
import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from core.rag_pipeline import RAGPipeline, RAGPipelineFactory

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="RAG Knowledge Retrieval API",
    description="åŸºäºQwen2-0.5B-Medical-MLXçš„RAGæ£€ç´¢å¢å¼ºç³»ç»ŸAPI",
    version="1.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€RAGæµç¨‹å®ä¾‹
rag_pipeline: Optional[RAGPipeline] = None

# Pydanticæ¨¡å‹å®šä¹‰
class DocumentModel(BaseModel):
    """æ–‡æ¡£æ¨¡å‹"""
    content: str = Field(..., description="æ–‡æ¡£å†…å®¹")
    title: Optional[str] = Field(None, description="æ–‡æ¡£æ ‡é¢˜")
    category: Optional[str] = Field(None, description="æ–‡æ¡£ç±»åˆ«")
    source: Optional[str] = Field(None, description="æ–‡æ¡£æ¥æº")
    metadata: Optional[Dict[str, Any]] = Field(None, description="é¢å¤–å…ƒæ•°æ®")
    type: Optional[str] = Field("text", description="æ–‡æ¡£ç±»å‹")

class ImageDocumentModel(BaseModel):
    """å›¾åƒæ–‡æ¡£æ¨¡å‹"""
    image_path: str = Field(..., description="å›¾åƒæ–‡ä»¶è·¯å¾„")
    title: Optional[str] = Field(None, description="å›¾åƒæ ‡é¢˜")
    category: Optional[str] = Field(None, description="å›¾åƒç±»åˆ«")
    source: Optional[str] = Field(None, description="å›¾åƒæ¥æº")
    metadata: Optional[Dict[str, Any]] = Field(None, description="é¢å¤–å…ƒæ•°æ®")

class QueryRequest(BaseModel):
    """æŸ¥è¯¢è¯·æ±‚æ¨¡å‹"""
    question: str = Field(..., description="ç”¨æˆ·é—®é¢˜")
    top_k: int = Field(5, description="æ£€ç´¢æ–‡æ¡£æ•°é‡", ge=1, le=20)
    response_type: str = Field("general", description="å“åº”ç±»å‹")
    similarity_threshold: float = Field(0.5, description="ç›¸ä¼¼åº¦é˜ˆå€¼", ge=0.0, le=1.0)

class ChatRequest(BaseModel):
    """å¯¹è¯è¯·æ±‚æ¨¡å‹"""
    messages: List[Dict[str, str]] = Field(..., description="å¯¹è¯å†å²")
    top_k: int = Field(5, description="æ£€ç´¢æ–‡æ¡£æ•°é‡", ge=1, le=20)

class SearchRequest(BaseModel):
    """æœç´¢è¯·æ±‚æ¨¡å‹"""
    query: str = Field(..., description="æœç´¢æŸ¥è¯¢")
    search_type: str = Field("semantic", description="æœç´¢ç±»å‹")
    top_k: int = Field(10, description="è¿”å›æ–‡æ¡£æ•°é‡", ge=1, le=50)

class BatchQueryRequest(BaseModel):
    """æ‰¹é‡æŸ¥è¯¢è¯·æ±‚æ¨¡å‹"""
    questions: List[str] = Field(..., description="é—®é¢˜åˆ—è¡¨")
    top_k: int = Field(5, description="æ£€ç´¢æ–‡æ¡£æ•°é‡", ge=1, le=20)

class ResponseModel(BaseModel):
    """å“åº”æ¨¡å‹"""
    success: bool = Field(..., description="æ˜¯å¦æˆåŠŸ")
    data: Optional[Dict[str, Any]] = Field(None, description="å“åº”æ•°æ®")
    message: Optional[str] = Field(None, description="å“åº”æ¶ˆæ¯")
    timestamp: str = Field(..., description="æ—¶é—´æˆ³")

# ä¾èµ–æ³¨å…¥
def get_rag_pipeline() -> RAGPipeline:
    """è·å–RAGæµç¨‹å®ä¾‹"""
    global rag_pipeline
    if rag_pipeline is None:
        raise HTTPException(status_code=503, detail="RAG pipeline not initialized")
    return rag_pipeline

# å¯åŠ¨äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–RAGæµç¨‹"""
    global rag_pipeline
    try:
        logger.info("Initializing RAG pipeline...")
        
        # åŠ è½½é…ç½®
        config_path = os.path.join(os.path.dirname(__file__), "config", "rag_config.json")
        rag_pipeline = RAGPipelineFactory.create_rag_pipeline(config_path)
        
        logger.info("RAG pipeline initialized successfully")
        
    except Exception as e:
        logger.error(f"Error initializing RAG pipeline: {e}")
        raise

# å…³é—­äº‹ä»¶
@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­æ—¶æ¸…ç†èµ„æº"""
    global rag_pipeline
    if rag_pipeline:
        try:
            rag_pipeline.clear_system()
            logger.info("RAG pipeline cleaned up")
        except Exception as e:
            logger.error(f"Error cleaning up RAG pipeline: {e}")

# APIè·¯ç”±
@app.get("/", response_model=ResponseModel)
async def root():
    """æ ¹è·¯å¾„ï¼Œè¿”å›APIä¿¡æ¯"""
    return ResponseModel(
        success=True,
        data={
            "api_name": "RAG Knowledge Retrieval API",
            "version": "1.0.0",
            "status": "running"
        },
        message="API is running",
        timestamp=datetime.now().isoformat()
    )

@app.get("/health", response_model=ResponseModel)
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    try:
        rag = get_rag_pipeline()
        stats = rag.get_system_stats()
        
        return ResponseModel(
            success=True,
            data=stats,
            message="System is healthy",
            timestamp=datetime.now().isoformat()
        )
    except Exception as e:
        return ResponseModel(
            success=False,
            message=f"Health check failed: {str(e)}",
            timestamp=datetime.now().isoformat()
        )

@app.post("/documents", response_model=ResponseModel)
async def add_documents(
    documents: List[DocumentModel],
    background_tasks: BackgroundTasks,
    rag: RAGPipeline = Depends(get_rag_pipeline)
):
    """æ·»åŠ æ–‡æ¡£åˆ°RAGç³»ç»Ÿ"""
    try:
        # è½¬æ¢æ–‡æ¡£æ ¼å¼
        doc_list = []
        for doc in documents:
            doc_dict = doc.dict()
            doc_list.append(doc_dict)
        
        # å¼‚æ­¥æ·»åŠ æ–‡æ¡£
        def add_docs():
            return rag.add_documents(doc_list)
        
        background_tasks.add_task(add_docs)
        
        return ResponseModel(
            success=True,
            data={"document_count": len(documents)},
            message=f"Added {len(documents)} documents",
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Error adding documents: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/documents/images", response_model=ResponseModel)
async def add_image_documents(
    documents: List[ImageDocumentModel],
    background_tasks: BackgroundTasks,
    rag: RAGPipeline = Depends(get_rag_pipeline)
):
    """æ·»åŠ å›¾åƒæ–‡æ¡£åˆ°RAGç³»ç»Ÿ"""
    try:
        # è½¬æ¢æ–‡æ¡£æ ¼å¼
        doc_list = []
        for doc in documents:
            doc_dict = doc.dict()
            doc_dict['type'] = 'image'
            doc_list.append(doc_dict)
        
        # å¼‚æ­¥æ·»åŠ æ–‡æ¡£
        def add_docs():
            return rag.add_documents(doc_list, vectorize_images=True)
        
        background_tasks.add_task(add_docs)
        
        return ResponseModel(
            success=True,
            data={"document_count": len(documents)},
            message=f"Added {len(documents)} image documents",
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Error adding image documents: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/query", response_model=ResponseModel)
async def query_documents(
    request: QueryRequest,
    rag: RAGPipeline = Depends(get_rag_pipeline)
):
    """æŸ¥è¯¢RAGç³»ç»Ÿ"""
    try:
        print("=" * 50)
        print("ğŸŒ APIæŸ¥è¯¢è¯·æ±‚å¼€å§‹")
        print("=" * 50)
        logger.info("å¼€å§‹å¤„ç†APIæŸ¥è¯¢è¯·æ±‚...")
        
        # 1. è·å–ç”¨æˆ·è¾“å…¥
        print("==========")
        print("è·å–ç”¨æˆ·è¾“å…¥å¼€å§‹")
        print("==========")
        logger.info(f"è·å–ç”¨æˆ·è¾“å…¥ç»†èŠ‚æ—¥å¿—ï¼šé—®é¢˜='{request.question}', top_k={request.top_k}, response_type='{request.response_type}'")
        logger.info("è·å–ç”¨æˆ·è¾“å…¥æˆåŠŸ")
        print("è·å–ç”¨æˆ·è¾“å…¥ç»“æŸ")
        print("==========")
        
        # 2. ç”¨æˆ·æ•°æ®å¤„ç†
        print("==========")
        print("ç”¨æˆ·æ•°æ®å¤„ç†å¼€å§‹")
        print("==========")
        logger.info("ç”¨æˆ·æ•°æ®å¤„ç†çš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹éªŒè¯è¯·æ±‚å‚æ•°")
        logger.info(f"é—®é¢˜é•¿åº¦: {len(request.question)} å­—ç¬¦")
        logger.info(f"æ£€ç´¢æ•°é‡: {request.top_k}")
        logger.info(f"å“åº”ç±»å‹: {request.response_type}")
        logger.info("ç”¨æˆ·æ•°æ®å¤„ç†å®Œæˆ")
        logger.info("ç”¨æˆ·æ•°æ®å¤„ç†æˆåŠŸ")
        print("==========")
        
        # 3. è°ƒç”¨RAGç³»ç»Ÿ
        print("==========")
        print("è°ƒç”¨RAGç³»ç»Ÿå¼€å§‹")
        print("==========")
        logger.info("è°ƒç”¨RAGç³»ç»Ÿçš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹è°ƒç”¨RAG Pipeline")
        
        try:
            # è®¾ç½®60ç§’è¶…æ—¶
            result = await asyncio.wait_for(
                asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: rag.query(
                        question=request.question,
                        top_k=request.top_k,
                        response_type=request.response_type,
                        similarity_threshold=request.similarity_threshold
                    )
                ),
                timeout=300.0
            )
            logger.info("RAGç³»ç»Ÿè°ƒç”¨å®Œæˆ")
            logger.info("è°ƒç”¨RAGç³»ç»ŸæˆåŠŸ")
        except asyncio.TimeoutError:
            logger.error("RAGç³»ç»Ÿè°ƒç”¨è¶…æ—¶")
            raise HTTPException(status_code=408, detail="æŸ¥è¯¢è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
        
        print("è°ƒç”¨RAGç³»ç»Ÿç»“æŸ")
        print("==========")
        
        # 4. è¿”å›ç”¨æˆ·ç»“æœ
        print("==========")
        print("è¿”å›ç”¨æˆ·ç»“æœå¼€å§‹")
        print("==========")
        logger.info("è¿”å›ç”¨æˆ·ç»“æœçš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹æ„å»ºAPIå“åº”")
        response = ResponseModel(
            success=True,
            data=result,
            message="Query completed successfully",
            timestamp=datetime.now().isoformat()
        )
        logger.info("APIå“åº”æ„å»ºå®Œæˆ")
        logger.info("è¿”å›ç”¨æˆ·ç»“æœæˆåŠŸ")
        print("è¿”å›ç”¨æˆ·ç»“æœç»“æŸ")
        print("==========")
        
        print("=" * 50)
        print("ğŸ‰ APIæŸ¥è¯¢è¯·æ±‚å®Œæˆ")
        print("=" * 50)
        logger.info("APIæŸ¥è¯¢è¯·æ±‚æˆåŠŸå®Œæˆ")
        
        return response
        
    except Exception as e:
        print("=" * 50)
        print("âŒ APIæŸ¥è¯¢è¯·æ±‚å¤±è´¥")
        print("=" * 50)
        logger.error(f"APIæŸ¥è¯¢è¯·æ±‚å¤±è´¥: {e}")
        logger.error(f"Error querying documents: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/chat", response_model=ResponseModel)
async def chat_with_rag(
    request: ChatRequest,
    rag: RAGPipeline = Depends(get_rag_pipeline)
):
    """ä¸RAGç³»ç»Ÿå¯¹è¯"""
    try:
        print("=" * 50)
        print("ğŸ’¬ APIå¯¹è¯è¯·æ±‚å¼€å§‹")
        print("=" * 50)
        logger.info("å¼€å§‹å¤„ç†APIå¯¹è¯è¯·æ±‚...")
        
        # 1. è·å–ç”¨æˆ·è¾“å…¥
        print("==========")
        print("è·å–ç”¨æˆ·è¾“å…¥å¼€å§‹")
        print("==========")
        logger.info(f"è·å–ç”¨æˆ·è¾“å…¥ç»†èŠ‚æ—¥å¿—ï¼šå¯¹è¯å†å²é•¿åº¦={len(request.messages)}, top_k={request.top_k}")
        for i, msg in enumerate(request.messages):
            role = msg.get('role', 'unknown')
            content = msg.get('content', '')[:50] + ('...' if len(msg.get('content', '')) > 50 else '')
            logger.info(f"æ¶ˆæ¯ {i+1}: è§’è‰²={role}, å†…å®¹='{content}'")
        logger.info("è·å–ç”¨æˆ·è¾“å…¥æˆåŠŸ")
        print("è·å–ç”¨æˆ·è¾“å…¥ç»“æŸ")
        print("==========")
        
        # 2. ç”¨æˆ·æ•°æ®å¤„ç†
        print("==========")
        print("ç”¨æˆ·æ•°æ®å¤„ç†å¼€å§‹")
        print("==========")
        logger.info("ç”¨æˆ·æ•°æ®å¤„ç†çš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹éªŒè¯å¯¹è¯è¯·æ±‚")
        logger.info(f"å¯¹è¯è½®æ•°: {len(request.messages)}")
        logger.info(f"æ£€ç´¢æ•°é‡: {request.top_k}")
        logger.info("ç”¨æˆ·æ•°æ®å¤„ç†å®Œæˆ")
        logger.info("ç”¨æˆ·æ•°æ®å¤„ç†æˆåŠŸ")
        print("==========")
        
        # 3. è°ƒç”¨RAGç³»ç»Ÿ
        print("==========")
        print("è°ƒç”¨RAGç³»ç»Ÿå¼€å§‹")
        print("==========")
        logger.info("è°ƒç”¨RAGç³»ç»Ÿçš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹è°ƒç”¨RAG Pipelineè¿›è¡Œå¯¹è¯")
        result = rag.chat(
            messages=request.messages,
            top_k=request.top_k
        )
        logger.info("RAGç³»ç»Ÿå¯¹è¯è°ƒç”¨å®Œæˆ")
        logger.info("è°ƒç”¨RAGç³»ç»ŸæˆåŠŸ")
        print("è°ƒç”¨RAGç³»ç»Ÿç»“æŸ")
        print("==========")
        
        # 4. è¿”å›ç”¨æˆ·ç»“æœ
        print("==========")
        print("è¿”å›ç”¨æˆ·ç»“æœå¼€å§‹")
        print("==========")
        logger.info("è¿”å›ç”¨æˆ·ç»“æœçš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹æ„å»ºå¯¹è¯APIå“åº”")
        response = ResponseModel(
            success=True,
            data=result,
            message="Chat completed successfully",
            timestamp=datetime.now().isoformat()
        )
        logger.info("å¯¹è¯APIå“åº”æ„å»ºå®Œæˆ")
        logger.info("è¿”å›ç”¨æˆ·ç»“æœæˆåŠŸ")
        print("è¿”å›ç”¨æˆ·ç»“æœç»“æŸ")
        print("==========")
        
        print("=" * 50)
        print("ğŸ‰ APIå¯¹è¯è¯·æ±‚å®Œæˆ")
        print("=" * 50)
        logger.info("APIå¯¹è¯è¯·æ±‚æˆåŠŸå®Œæˆ")
        
        return response
        
    except Exception as e:
        print("=" * 50)
        print("âŒ APIå¯¹è¯è¯·æ±‚å¤±è´¥")
        print("=" * 50)
        logger.error(f"APIå¯¹è¯è¯·æ±‚å¤±è´¥: {e}")
        logger.error(f"Error in chat: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/search", response_model=ResponseModel)
async def search_documents(
    request: SearchRequest,
    rag: RAGPipeline = Depends(get_rag_pipeline)
):
    """æœç´¢æ–‡æ¡£"""
    try:
        results = rag.search_documents(
            query=request.query,
            search_type=request.search_type,
            top_k=request.top_k
        )
        
        return ResponseModel(
            success=True,
            data={"documents": results, "count": len(results)},
            message="Search completed successfully",
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Error searching documents: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/batch_query", response_model=ResponseModel)
async def batch_query_documents(
    request: BatchQueryRequest,
    rag: RAGPipeline = Depends(get_rag_pipeline)
):
    """æ‰¹é‡æŸ¥è¯¢"""
    try:
        print("=" * 50)
        print("ğŸ“¦ APIæ‰¹é‡æŸ¥è¯¢è¯·æ±‚å¼€å§‹")
        print("=" * 50)
        logger.info("å¼€å§‹å¤„ç†APIæ‰¹é‡æŸ¥è¯¢è¯·æ±‚...")
        
        # 1. è·å–ç”¨æˆ·è¾“å…¥
        print("==========")
        print("è·å–ç”¨æˆ·è¾“å…¥å¼€å§‹")
        print("==========")
        logger.info(f"è·å–ç”¨æˆ·è¾“å…¥ç»†èŠ‚æ—¥å¿—ï¼šé—®é¢˜æ•°é‡={len(request.questions)}, top_k={request.top_k}")
        for i, question in enumerate(request.questions):
            logger.info(f"é—®é¢˜ {i+1}: '{question[:50]}{'...' if len(question) > 50 else ''}'")
        logger.info("è·å–ç”¨æˆ·è¾“å…¥æˆåŠŸ")
        print("è·å–ç”¨æˆ·è¾“å…¥ç»“æŸ")
        print("==========")
        
        # 2. ç”¨æˆ·æ•°æ®å¤„ç†
        print("==========")
        print("ç”¨æˆ·æ•°æ®å¤„ç†å¼€å§‹")
        print("==========")
        logger.info("ç”¨æˆ·æ•°æ®å¤„ç†çš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹éªŒè¯æ‰¹é‡æŸ¥è¯¢è¯·æ±‚")
        logger.info(f"é—®é¢˜æ€»æ•°: {len(request.questions)}")
        logger.info(f"æ£€ç´¢æ•°é‡: {request.top_k}")
        logger.info("ç”¨æˆ·æ•°æ®å¤„ç†å®Œæˆ")
        logger.info("ç”¨æˆ·æ•°æ®å¤„ç†æˆåŠŸ")
        print("==========")
        
        # 3. è°ƒç”¨RAGç³»ç»Ÿ
        print("==========")
        print("è°ƒç”¨RAGç³»ç»Ÿå¼€å§‹")
        print("==========")
        logger.info("è°ƒç”¨RAGç³»ç»Ÿçš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹è°ƒç”¨RAG Pipelineè¿›è¡Œæ‰¹é‡æŸ¥è¯¢")
        results = rag.batch_query(
            questions=request.questions,
            top_k=request.top_k
        )
        logger.info("RAGç³»ç»Ÿæ‰¹é‡æŸ¥è¯¢è°ƒç”¨å®Œæˆ")
        logger.info("è°ƒç”¨RAGç³»ç»ŸæˆåŠŸ")
        print("è°ƒç”¨RAGç³»ç»Ÿç»“æŸ")
        print("==========")
        
        # 4. è¿”å›ç”¨æˆ·ç»“æœ
        print("==========")
        print("è¿”å›ç”¨æˆ·ç»“æœå¼€å§‹")
        print("==========")
        logger.info("è¿”å›ç”¨æˆ·ç»“æœçš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹æ„å»ºæ‰¹é‡æŸ¥è¯¢APIå“åº”")
        response = ResponseModel(
            success=True,
            data={"results": results, "count": len(results)},
            message="Batch query completed successfully",
            timestamp=datetime.now().isoformat()
        )
        logger.info(f"æ‰¹é‡æŸ¥è¯¢APIå“åº”æ„å»ºå®Œæˆï¼Œç»“æœæ•°é‡: {len(results)}")
        logger.info("è¿”å›ç”¨æˆ·ç»“æœæˆåŠŸ")
        print("è¿”å›ç”¨æˆ·ç»“æœç»“æŸ")
        print("==========")
        
        print("=" * 50)
        print("ğŸ‰ APIæ‰¹é‡æŸ¥è¯¢è¯·æ±‚å®Œæˆ")
        print("=" * 50)
        logger.info("APIæ‰¹é‡æŸ¥è¯¢è¯·æ±‚æˆåŠŸå®Œæˆ")
        
        return response
        
    except Exception as e:
        print("=" * 50)
        print("âŒ APIæ‰¹é‡æŸ¥è¯¢è¯·æ±‚å¤±è´¥")
        print("=" * 50)
        logger.error(f"APIæ‰¹é‡æŸ¥è¯¢è¯·æ±‚å¤±è´¥: {e}")
        logger.error(f"Error in batch query: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/stats", response_model=ResponseModel)
async def get_system_stats(rag: RAGPipeline = Depends(get_rag_pipeline)):
    """è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯"""
    try:
        stats = rag.get_system_stats()
        
        return ResponseModel(
            success=True,
            data=stats,
            message="Statistics retrieved successfully",
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Error getting stats: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/save", response_model=ResponseModel)
async def save_system(
    save_dir: str,
    rag: RAGPipeline = Depends(get_rag_pipeline)
):
    """ä¿å­˜ç³»ç»ŸçŠ¶æ€"""
    try:
        rag.save_system(save_dir)
        
        return ResponseModel(
            success=True,
            data={"save_directory": save_dir},
            message="System saved successfully",
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Error saving system: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/load", response_model=ResponseModel)
async def load_system(
    save_dir: str,
    rag: RAGPipeline = Depends(get_rag_pipeline)
):
    """åŠ è½½ç³»ç»ŸçŠ¶æ€"""
    try:
        rag.load_system(save_dir)
        
        return ResponseModel(
            success=True,
            data={"load_directory": save_dir},
            message="System loaded successfully",
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Error loading system: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.delete("/clear", response_model=ResponseModel)
async def clear_system(rag: RAGPipeline = Depends(get_rag_pipeline)):
    """æ¸…ç©ºç³»ç»Ÿæ•°æ®"""
    try:
        rag.clear_system()
        
        return ResponseModel(
            success=True,
            message="System cleared successfully",
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Error clearing system: {e}")
        raise HTTPException(status_code=500, detail=str(e))

# é”™è¯¯å¤„ç†
@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """å…¨å±€å¼‚å¸¸å¤„ç†"""
    logger.error(f"Global exception: {exc}")
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "message": "Internal server error",
            "timestamp": datetime.now().isoformat()
        }
    )

@app.post("/query/stream")
async def query_documents_stream(
    request: QueryRequest,
    rag: RAGPipeline = Depends(get_rag_pipeline)
):
    """æµå¼æŸ¥è¯¢RAGç³»ç»Ÿ"""
    try:
        print("=" * 50)
        print("ğŸŒ APIæµå¼æŸ¥è¯¢è¯·æ±‚å¼€å§‹")
        print("=" * 50)
        logger.info("å¼€å§‹å¤„ç†APIæµå¼æŸ¥è¯¢è¯·æ±‚...")
        
        def generate_stream():
            try:
                # è°ƒç”¨RAGç³»ç»Ÿçš„æµå¼æŸ¥è¯¢
                for chunk in rag.query_stream(
                    question=request.question,
                    top_k=request.top_k,
                    response_type=request.response_type,
                    similarity_threshold=request.similarity_threshold
                ):
                    # å°†chunkè½¬æ¢ä¸ºJSONæ ¼å¼
                    chunk_json = json.dumps(chunk, ensure_ascii=False) + "\n"
                    yield chunk_json
                    
            except Exception as e:
                logger.error(f"æµå¼æŸ¥è¯¢å‡ºé”™ï¼š{e}")
                error_chunk = {
                    "type": "error",
                    "message": f"æŸ¥è¯¢å‡ºé”™ï¼š{str(e)}"
                }
                yield json.dumps(error_chunk, ensure_ascii=False) + "\n"
        
        return StreamingResponse(
            generate_stream(),
            media_type="application/x-ndjson",
            headers={
                "Cache-Control": "no-cache",
                "Connection": "keep-alive",
                "Access-Control-Allow-Origin": "*",
                "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
                "Access-Control-Allow-Headers": "*",
            }
        )
        
    except Exception as e:
        logger.error(f"æµå¼æŸ¥è¯¢APIå‡ºé”™ï¼š{e}")
        raise HTTPException(status_code=500, detail=f"æµå¼æŸ¥è¯¢å‡ºé”™ï¼š{str(e)}")


if __name__ == "__main__":
    # è¿è¡ŒAPIæœåŠ¡å™¨
    uvicorn.run(
        "rag_api:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
