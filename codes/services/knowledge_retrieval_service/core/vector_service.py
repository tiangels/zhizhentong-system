"""
å‘é‡åŒ–æœåŠ¡æ¨¡å—
è´Ÿè´£æ–‡æœ¬å’Œå›¾åƒçš„å‘é‡åŒ–å¤„ç†ï¼Œä¸ºRAGæ£€ç´¢æä¾›å‘é‡è¡¨ç¤º
æ³¨æ„ï¼šæ­¤æ¨¡å—ç°åœ¨è°ƒç”¨æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡ï¼Œé¿å…é‡å¤å®ç°
"""

import os
import sys
import json
import logging
import numpy as np
from typing import List, Dict, Any, Optional, Union
from pathlib import Path
from PIL import Image

# æ·»åŠ æ„å»ºçŸ¥è¯†åº“æ¨¡å—è·¯å¾„
project_root = Path(__file__).parent.parent.parent.parent.parent
embedding_models_path = project_root / "codes" / "ai_models" / "embedding_models"
sys.path.insert(0, str(embedding_models_path))

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¯¼å…¥æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡
try:
    # ç›´æ¥å¯¼å…¥ï¼Œä¸ä½¿ç”¨ç›¸å¯¹å¯¼å…¥
    import core.vectorization_service as vs_module
    import core.medical_knowledge_manager as km_module
    import processors.document_chunker as dc_module
    
    VectorizationService = vs_module.VectorizationService
    MedicalKnowledgeManager = km_module.MedicalKnowledgeManager
    DocumentChunker = dc_module.DocumentChunker
    create_medical_chunker = dc_module.create_medical_chunker
    
    EMBEDDING_SERVICE_AVAILABLE = True
    logger.info("æˆåŠŸå¯¼å…¥æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡")
except ImportError as e:
    logger.warning(f"æ— æ³•å¯¼å…¥æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡: {e}")
    EMBEDDING_SERVICE_AVAILABLE = False


class VectorService:
    """å‘é‡åŒ–æœåŠ¡ç±»ï¼Œè´Ÿè´£æ–‡æœ¬å’Œå›¾åƒçš„å‘é‡åŒ–å¤„ç†"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–å‘é‡åŒ–æœåŠ¡
        
        Args:
            config: é…ç½®å­—å…¸ï¼ŒåŒ…å«æ¨¡å‹è·¯å¾„ã€è®¾å¤‡ç­‰é…ç½®ä¿¡æ¯
        """
        self.config = config
        self.vector_dim = config.get('vector_dim', 768)  # é»˜è®¤ç»´åº¦ï¼Œä¼šæ ¹æ®å®é™…æ¨¡å‹è°ƒæ•´
        self.batch_size = config.get('batch_size', 32)
        
        # åˆå§‹åŒ–æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡
        self.embedding_service = None
        self.knowledge_manager = None
        self.document_chunker = None
        
        if EMBEDDING_SERVICE_AVAILABLE:
            try:
                # åˆå§‹åŒ–åŒ»ç–—çŸ¥è¯†ç®¡ç†å™¨
                self.knowledge_manager = MedicalKnowledgeManager()
                
                # åˆå§‹åŒ–å‘é‡åŒ–æœåŠ¡
                self.embedding_service = VectorizationService()
                
                # åˆå§‹åŒ–æ–‡æ¡£åˆ‡åˆ†å™¨
                self.document_chunker = create_medical_chunker()
                
                logger.info("æˆåŠŸåˆå§‹åŒ–æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡")
            except Exception as e:
                logger.error(f"åˆå§‹åŒ–æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡å¤±è´¥: {e}")
                self._init_fallback_service()
        else:
            logger.warning("æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡ä¸å¯ç”¨ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ¡ˆ")
            self._init_fallback_service()
        
        # å‘é‡æ•°æ®åº“
        self.vector_db = None
        self.db_path = self.config.get('vector_db_path', '../../../datas/vector_databases/text')
        self._init_vector_db()
    
    def _init_fallback_service(self):
        """åˆå§‹åŒ–å¤‡ç”¨å‘é‡åŒ–æœåŠ¡ï¼ˆå½“æ„å»ºçŸ¥è¯†åº“æ¨¡å—ä¸å¯ç”¨æ—¶ï¼‰"""
        try:
            import torch
            from sentence_transformers import SentenceTransformer
            import os
            
            self.device = self.config.get('device', 'cuda' if torch.cuda.is_available() else 'cpu')
            self.text_model = None
            self.image_model = None
            
            # å°è¯•åŠ è½½æ–‡æœ¬å‘é‡åŒ–æ¨¡å‹ï¼ˆæœ¬åœ°ä¼˜å…ˆç­–ç•¥ï¼‰
            text_model_path = self.config.get('text_model_path', 'sentence-transformers/all-MiniLM-L6-v2')
            self.text_model = self._load_model_with_fallback(text_model_path, 'text')
            
            # è®¾ç½®æ¨¡å‹åç§°ç”¨äºChromaDB
            self.model_name = text_model_path
            
            # å°è¯•åŠ è½½å›¾åƒå‘é‡åŒ–æ¨¡å‹ï¼ˆæœ¬åœ°ä¼˜å…ˆç­–ç•¥ï¼‰
            image_model_path = self.config.get('image_model_path', 'clip-ViT-B-32')
            self.image_model = self._load_model_with_fallback(image_model_path, 'image')
            
            # æ ¹æ®å®é™…åŠ è½½çš„æ¨¡å‹è°ƒæ•´å‘é‡ç»´åº¦
            self._adjust_vector_dimension()
            
            logger.info("Fallback models loaded successfully")
            
        except Exception as e:
            logger.error(f"Error loading fallback models: {e}")
            # å¦‚æœæ‰€æœ‰æ¨¡å‹éƒ½å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„TF-IDFä½œä¸ºæœ€åçš„åå¤‡
            self._init_simple_fallback()
            self._adjust_vector_dimension()
    
    def _load_model_with_fallback(self, model_path: str, model_type: str):
        """ä½¿ç”¨æœ¬åœ°ä¼˜å…ˆç­–ç•¥åŠ è½½æ¨¡å‹"""
        try:
            from sentence_transformers import SentenceTransformer
            import os
            import tempfile
            
            # 0. é¦–å…ˆæ£€æŸ¥é…ç½®æ–‡ä»¶ä¸­æŒ‡å®šçš„ç»å¯¹è·¯å¾„
            if os.path.isabs(model_path) and os.path.exists(model_path):
                logger.info(f"Found configured {model_type} model at {model_path}")
                return SentenceTransformer(model_path, device=self.device)
            
            # 1. æ£€æŸ¥æœ¬åœ°ç¼“å­˜ç›®å½•
            cache_dir = os.path.expanduser("~/.cache/huggingface/transformers")
            local_path = os.path.join(cache_dir, model_path.replace("/", "--"))
            
            if os.path.exists(local_path):
                logger.info(f"Found local {model_type} model at {local_path}")
                return SentenceTransformer(local_path, device=self.device)
            
            # 2. æ£€æŸ¥é¡¹ç›®å†…çš„æ¨¡å‹ç›®å½•
            project_models_dir = Path(__file__).parent.parent.parent.parent / "models" / "embedding"
            project_model_path = project_models_dir / model_path.replace("/", "_")
            
            if project_model_path.exists():
                logger.info(f"Found project {model_type} model at {project_model_path}")
                return SentenceTransformer(str(project_model_path), device=self.device)
            
            # 3. å°è¯•ä»Hugging Faceä¸‹è½½ï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            logger.info(f"Attempting to download {model_type} model from Hugging Face: {model_path}")
            try:
                # è®¾ç½®ç¦»çº¿æ¨¡å¼ä¸ºFalseï¼Œå…è®¸ä¸‹è½½
                model = SentenceTransformer(model_path, device=self.device)
                logger.info(f"Successfully downloaded {model_type} model: {model_path}")
                return model
            except Exception as download_error:
                logger.warning(f"Failed to download {model_type} model: {download_error}")
                raise download_error
                
        except Exception as e:
            logger.error(f"Failed to load {model_type} model: {e}")
            return None
    
    def _init_simple_fallback(self):
        """åˆå§‹åŒ–ç®€å•çš„åå¤‡å‘é‡åŒ–æœåŠ¡ï¼ˆTF-IDFï¼‰"""
        try:
            from sklearn.feature_extraction.text import TfidfVectorizer
            import numpy as np
            
            logger.info("Initializing simple TF-IDF fallback model")
            
            # ä½¿ç”¨TF-IDFä½œä¸ºæœ€åçš„åå¤‡
            self.text_model = TfidfVectorizer(
                max_features=1000,
                stop_words=None,  # ä¸­æ–‡ä¸éœ€è¦è‹±æ–‡åœç”¨è¯
                ngram_range=(1, 2),
                lowercase=False  # ä¿æŒåŸå§‹å¤§å°å†™
            )
            self.image_model = None  # å›¾åƒå¤„ç†æš‚æ—¶è·³è¿‡
            self.model_name = "tfidf-fallback"
            
            # æ ‡è®°ä½¿ç”¨ç®€å•æ¨¡å‹
            self._use_simple_model = True
            
            logger.info("Simple TF-IDF fallback model initialized successfully")
            
        except Exception as e:
            logger.error(f"Failed to initialize simple fallback model: {e}")
            # æœ€åçš„æœ€åï¼Œè®¾ç½®ä¸ºNone
            self.text_model = None
            self.image_model = None
            self.model_name = "none"
            self._use_simple_model = False
    
    def _adjust_vector_dimension(self):
        """æ ¹æ®å®é™…åŠ è½½çš„æ¨¡å‹è°ƒæ•´å‘é‡ç»´åº¦"""
        try:
            if hasattr(self, '_use_simple_model') and self._use_simple_model:
                # TF-IDFæ¨¡å‹çš„ç»´åº¦ç”±max_featureså†³å®š
                if hasattr(self.text_model, 'max_features'):
                    self.vector_dim = self.text_model.max_features
                else:
                    self.vector_dim = 1000  # é»˜è®¤TF-IDFç»´åº¦
                logger.info(f"Adjusted vector dimension for TF-IDF model: {self.vector_dim}")
            elif self.text_model and hasattr(self.text_model, 'get_sentence_embedding_dimension'):
                # SentenceTransformeræ¨¡å‹
                self.vector_dim = self.text_model.get_sentence_embedding_dimension()
                logger.info(f"Adjusted vector dimension for SentenceTransformer model: {self.vector_dim}")
            elif self.embedding_service:
                # æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡
                self.vector_dim = self.config.get('vector_dim', 768)
                logger.info(f"Using configured vector dimension for embedding service: {self.vector_dim}")
            else:
                # ä¿æŒé»˜è®¤ç»´åº¦
                logger.info(f"Using default vector dimension: {self.vector_dim}")
        except Exception as e:
            logger.warning(f"Failed to adjust vector dimension: {e}")
            # ä¿æŒé»˜è®¤ç»´åº¦
            pass
    
    def _init_vector_db(self):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
        try:
            from langchain_chroma import Chroma
            from langchain_core.embeddings import Embeddings
            
            # åˆ›å»ºè‡ªå®šä¹‰åµŒå…¥å‡½æ•°ï¼Œä½¿ç”¨å·²ç»åŠ è½½çš„æ¨¡å‹
            class CustomEmbeddings(Embeddings):
                def __init__(self, model):
                    self.model = model
                
                def embed_documents(self, texts):
                    """åµŒå…¥æ–‡æ¡£åˆ—è¡¨"""
                    if self.model is None:
                        # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›éšæœºå‘é‡
                        import numpy as np
                        return [np.random.randn(768).tolist() for _ in texts]
                    return [self.model.encode(text).tolist() for text in texts]
                
                def embed_query(self, text):
                    """åµŒå…¥æŸ¥è¯¢æ–‡æœ¬"""
                    if self.model is None:
                        # å¦‚æœæ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›éšæœºå‘é‡
                        import numpy as np
                        return np.random.randn(768).tolist()
                    return self.model.encode(text).tolist()
            
            # åˆ›å»ºåµŒå…¥å‡½æ•°
            if hasattr(self, 'text_model') and self.text_model is not None:
                self.embedding_function = CustomEmbeddings(self.text_model)
                logger.info("Using loaded text model for embeddings")
            else:
                # å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨ç©ºæ¨¡å‹
                self.embedding_function = CustomEmbeddings(None)
                logger.warning("No text model available, using random embeddings")
            
            # åˆ›å»ºChromaDBå‘é‡æ•°æ®åº“
            self.vector_db = Chroma(
                persist_directory=self.db_path,
                embedding_function=self.embedding_function,
                collection_name="knowledge_retrieval"
            )
            logger.info("ChromaDB vector database initialized")
        except Exception as e:
            logger.error(f"Error initializing vector database: {e}")
            raise
    
    def text_to_vector(self, text: str) -> np.ndarray:
        """
        å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            
        Returns:
            æ–‡æœ¬å‘é‡
        """
        try:
            print("=" * 50)
            print("ğŸ”¤ æ–‡æœ¬å‘é‡åŒ–å¼€å§‹")
            print("=" * 50)
            logger.info("å¼€å§‹æ–‡æœ¬å‘é‡åŒ–...")
            
            # 1. è·å–ç”¨æˆ·è¾“å…¥
            print("==========")
            print("è·å–ç”¨æˆ·è¾“å…¥å¼€å§‹")
            print("==========")
            logger.info(f"è·å–ç”¨æˆ·è¾“å…¥ç»†èŠ‚æ—¥å¿—ï¼šæ–‡æœ¬é•¿åº¦={len(text)} å­—ç¬¦")
            logger.info(f"æ–‡æœ¬å†…å®¹: '{text[:100]}{'...' if len(text) > 100 else ''}'")
            logger.info("è·å–ç”¨æˆ·è¾“å…¥æˆåŠŸ")
            print("è·å–ç”¨æˆ·è¾“å…¥ç»“æŸ")
            print("==========")
            
            # 2. ç”¨æˆ·æ•°æ®å¤„ç†
            print("==========")
            print("ç”¨æˆ·æ•°æ®å¤„ç†å¼€å§‹")
            print("==========")
            logger.info("ç”¨æˆ·æ•°æ®å¤„ç†çš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹é¢„å¤„ç†æ–‡æœ¬")
            
            if not text or not text.strip():
                logger.warning("Empty text provided for vectorization")
                return np.zeros(self.vector_dim)
            
            logger.info(f"æ–‡æœ¬é¢„å¤„ç†å®Œæˆï¼Œæœ‰æ•ˆé•¿åº¦: {len(text.strip())} å­—ç¬¦")
            logger.info("ç”¨æˆ·æ•°æ®å¤„ç†å®Œæˆ")
            logger.info("ç”¨æˆ·æ•°æ®å¤„ç†æˆåŠŸ")
            print("==========")
            
            # 3. æ–‡æœ¬å‘é‡åŒ–
            print("==========")
            print("æ–‡æœ¬å‘é‡åŒ–å¼€å§‹")
            print("==========")
            logger.info("æ–‡æœ¬å‘é‡åŒ–çš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡")
            
            # ä¼˜å…ˆä½¿ç”¨æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡
            if self.embedding_service:
                logger.info("ä½¿ç”¨æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡")
                vectors = self.embedding_service.process_texts([text])
                if len(vectors) > 0:
                    vector = vectors[0]
                    logger.info(f"å‘é‡åŒ–å®Œæˆï¼Œå‘é‡ç»´åº¦: {len(vector)}")
                    logger.info("æ–‡æœ¬å‘é‡åŒ–æˆåŠŸ")
                    print("æ–‡æœ¬å‘é‡åŒ–ç»“æŸ")
                    print("==========")
                    
                    # 4. è¿”å›ç”¨æˆ·ç»“æœ
                    print("==========")
                    print("è¿”å›ç”¨æˆ·ç»“æœå¼€å§‹")
                    print("==========")
                    logger.info("è¿”å›ç”¨æˆ·ç»“æœçš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹æ„å»ºå‘é‡åŒ–ç»“æœ")
                    logger.info("å‘é‡åŒ–ç»“æœ: æˆåŠŸ")
                    logger.info("è¿”å›ç”¨æˆ·ç»“æœæˆåŠŸ")
                    print("è¿”å›ç”¨æˆ·ç»“æœç»“æŸ")
                    print("==========")
                    
                    print("=" * 50)
                    print("ğŸ‰ æ–‡æœ¬å‘é‡åŒ–å®Œæˆ")
                    print("=" * 50)
                    logger.info("æ–‡æœ¬å‘é‡åŒ–æˆåŠŸå®Œæˆ")
                    
                    return vector
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æœ¬åœ°æ¨¡å‹
            if self.text_model:
                logger.info("ä½¿ç”¨å¤‡ç”¨å‘é‡åŒ–æœåŠ¡")
                
                # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç®€å•TF-IDFæ¨¡å‹
                if hasattr(self, '_use_simple_model') and self._use_simple_model:
                    logger.info("ä½¿ç”¨TF-IDFç®€å•æ¨¡å‹è¿›è¡Œå‘é‡åŒ–")
                    # å¯¹äºTF-IDFï¼Œéœ€è¦å…ˆfitï¼Œç„¶åtransform
                    if not hasattr(self, '_tfidf_fitted'):
                        # ä½¿ç”¨ä¸€äº›ç¤ºä¾‹æ–‡æœ¬è¿›è¡Œfit
                        sample_texts = [text, "ç¤ºä¾‹æ–‡æœ¬", "æµ‹è¯•æ–‡æœ¬"]
                        self.text_model.fit(sample_texts)
                        self._tfidf_fitted = True
                    
                    vector = self.text_model.transform([text]).toarray().flatten()
                    # å½’ä¸€åŒ–å‘é‡
                    if np.linalg.norm(vector) > 0:
                        vector = vector / np.linalg.norm(vector)
                else:
                    # ä½¿ç”¨SentenceTransformeræ¨¡å‹
                    vector = self.text_model.encode([text], convert_to_tensor=True)
                    vector = vector.cpu().numpy().flatten()
                    # å½’ä¸€åŒ–å‘é‡
                    vector = vector / np.linalg.norm(vector)
                
                logger.info(f"å¤‡ç”¨å‘é‡åŒ–å®Œæˆï¼Œå‘é‡ç»´åº¦: {len(vector)}")
                logger.info("æ–‡æœ¬å‘é‡åŒ–æˆåŠŸ")
                print("æ–‡æœ¬å‘é‡åŒ–ç»“æŸ")
                print("==========")
                
                # 4. è¿”å›ç”¨æˆ·ç»“æœ
                print("==========")
                print("è¿”å›ç”¨æˆ·ç»“æœå¼€å§‹")
                print("==========")
                logger.info("è¿”å›ç”¨æˆ·ç»“æœçš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹æ„å»ºå‘é‡åŒ–ç»“æœ")
                logger.info("å‘é‡åŒ–ç»“æœ: æˆåŠŸ")
                logger.info("è¿”å›ç”¨æˆ·ç»“æœæˆåŠŸ")
                print("è¿”å›ç”¨æˆ·ç»“æœç»“æŸ")
                print("==========")
                
                print("=" * 50)
                print("ğŸ‰ æ–‡æœ¬å‘é‡åŒ–å®Œæˆ")
                print("=" * 50)
                logger.info("æ–‡æœ¬å‘é‡åŒ–æˆåŠŸå®Œæˆ")
                
                return vector
            
            # å¦‚æœéƒ½ä¸å¯ç”¨ï¼Œè¿”å›é›¶å‘é‡
            logger.warning("No vectorization service available, returning zero vector")
            logger.info("æ–‡æœ¬å‘é‡åŒ–æˆåŠŸ")
            print("æ–‡æœ¬å‘é‡åŒ–ç»“æŸ")
            print("==========")
            
            # 4. è¿”å›ç”¨æˆ·ç»“æœ
            print("==========")
            print("è¿”å›ç”¨æˆ·ç»“æœå¼€å§‹")
            print("==========")
            logger.info("è¿”å›ç”¨æˆ·ç»“æœçš„ç»†èŠ‚æ—¥å¿—ï¼šå¼€å§‹æ„å»ºå‘é‡åŒ–ç»“æœ")
            logger.info("å‘é‡åŒ–ç»“æœ: é›¶å‘é‡")
            logger.info("è¿”å›ç”¨æˆ·ç»“æœæˆåŠŸ")
            print("è¿”å›ç”¨æˆ·ç»“æœç»“æŸ")
            print("==========")
            
            print("=" * 50)
            print("ğŸ‰ æ–‡æœ¬å‘é‡åŒ–å®Œæˆ")
            print("=" * 50)
            logger.info("æ–‡æœ¬å‘é‡åŒ–æˆåŠŸå®Œæˆ")
            
            return np.zeros(self.vector_dim)
            
        except Exception as e:
            print("=" * 50)
            print("âŒ æ–‡æœ¬å‘é‡åŒ–å¤±è´¥")
            print("=" * 50)
            logger.error(f"æ–‡æœ¬å‘é‡åŒ–å¤±è´¥: {e}")
            logger.error(f"Error converting text to vector: {e}")
            return np.zeros(self.vector_dim)
    
    def image_to_vector(self, image_path: str) -> np.ndarray:
        """
        å°†å›¾åƒè½¬æ¢ä¸ºå‘é‡
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            
        Returns:
            å›¾åƒå‘é‡
        """
        try:
            if not os.path.exists(image_path):
                logger.warning(f"Image file not found: {image_path}")
                return np.zeros(self.vector_dim)
            
            # åŠ è½½å’Œé¢„å¤„ç†å›¾åƒ
            image = Image.open(image_path).convert('RGB')
            
            # ä½¿ç”¨CLIPæ¨¡å‹è¿›è¡Œå›¾åƒå‘é‡åŒ–
            vector = self.image_model.encode([image], convert_to_tensor=True)
            vector = vector.cpu().numpy().flatten()
            
            # å½’ä¸€åŒ–å‘é‡
            vector = vector / np.linalg.norm(vector)
            
            return vector
            
        except Exception as e:
            logger.error(f"Error converting image to vector: {e}")
            return np.zeros(self.vector_dim)
    
    def batch_text_to_vectors(self, texts: List[str]) -> np.ndarray:
        """
        æ‰¹é‡å°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            
        Returns:
            æ–‡æœ¬å‘é‡çŸ©é˜µ
        """
        try:
            if not texts:
                return np.array([])
            
            # ä¼˜å…ˆä½¿ç”¨æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡
            if self.embedding_service:
                vectors = self.embedding_service.process_texts(texts)
                if len(vectors) > 0:
                    return vectors
            
            # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æœ¬åœ°æ¨¡å‹
            if self.text_model:
                # è¿‡æ»¤ç©ºæ–‡æœ¬
                valid_texts = [text for text in texts if text and text.strip()]
                if not valid_texts:
                    return np.zeros((len(texts), self.vector_dim))
                
                # æ‰¹é‡å‘é‡åŒ–
                vectors = self.text_model.encode(valid_texts, convert_to_tensor=True, batch_size=self.batch_size)
                vectors = vectors.cpu().numpy()
                
                # å½’ä¸€åŒ–å‘é‡
                vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)
                
                # å¦‚æœåŸå§‹åˆ—è¡¨ä¸­æœ‰ç©ºæ–‡æœ¬ï¼Œéœ€è¦è¡¥é½
                if len(valid_texts) < len(texts):
                    full_vectors = np.zeros((len(texts), self.vector_dim))
                    valid_idx = 0
                    for i, text in enumerate(texts):
                        if text and text.strip():
                            full_vectors[i] = vectors[valid_idx]
                            valid_idx += 1
                    vectors = full_vectors
                
                return vectors
            
            # å¦‚æœéƒ½ä¸å¯ç”¨ï¼Œè¿”å›é›¶å‘é‡çŸ©é˜µ
            logger.warning("No vectorization service available, returning zero vectors")
            return np.zeros((len(texts), self.vector_dim))
            
        except Exception as e:
            logger.error(f"Error in batch text vectorization: {e}")
            return np.zeros((len(texts), self.vector_dim))
    
    def batch_image_to_vectors(self, image_paths: List[str]) -> np.ndarray:
        """
        æ‰¹é‡å°†å›¾åƒè½¬æ¢ä¸ºå‘é‡
        
        Args:
            image_paths: å›¾åƒè·¯å¾„åˆ—è¡¨
            
        Returns:
            å›¾åƒå‘é‡çŸ©é˜µ
        """
        try:
            if not image_paths:
                return np.array([])
            
            # è¿‡æ»¤æœ‰æ•ˆå›¾åƒè·¯å¾„
            valid_paths = [path for path in image_paths if os.path.exists(path)]
            if not valid_paths:
                return np.zeros((len(image_paths), self.vector_dim))
            
            # åŠ è½½å›¾åƒ
            images = []
            valid_indices = []
            for i, path in enumerate(image_paths):
                if os.path.exists(path):
                    try:
                        image = Image.open(path).convert('RGB')
                        images.append(image)
                        valid_indices.append(i)
                    except Exception as e:
                        logger.warning(f"Error loading image {path}: {e}")
            
            if not images:
                return np.zeros((len(image_paths), self.vector_dim))
            
            # æ‰¹é‡å‘é‡åŒ–
            vectors = self.image_model.encode(images, convert_to_tensor=True, batch_size=self.batch_size)
            vectors = vectors.cpu().numpy()
            
            # å½’ä¸€åŒ–å‘é‡
            vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)
            
            # è¡¥é½ç¼ºå¤±çš„å‘é‡
            if len(valid_indices) < len(image_paths):
                full_vectors = np.zeros((len(image_paths), self.vector_dim))
                for i, valid_idx in enumerate(valid_indices):
                    full_vectors[valid_idx] = vectors[i]
                vectors = full_vectors
            
            return vectors
            
        except Exception as e:
            logger.error(f"Error in batch image vectorization: {e}")
            return np.zeros((len(image_paths), self.vector_dim))
    
    def add_vectors_to_db(self, vectors: np.ndarray, metadata: List[Dict[str, Any]]):
        """
        å°†å‘é‡æ·»åŠ åˆ°å‘é‡æ•°æ®åº“
        
        Args:
            vectors: å‘é‡çŸ©é˜µ
            metadata: å…ƒæ•°æ®åˆ—è¡¨
        """
        try:
            if vectors.size == 0:
                return
            
            # ç¡®ä¿å‘é‡æ˜¯äºŒç»´çš„
            if vectors.ndim == 1:
                vectors = vectors.reshape(1, -1)
            
            # ä¸ºChromaDBå‡†å¤‡æ–‡æ¡£å’Œå…ƒæ•°æ®
            documents = []
            metadatas = []
            
            for i, meta in enumerate(metadata):
                # ä»å…ƒæ•°æ®ä¸­æå–æ–‡æ¡£å†…å®¹
                doc_content = meta.get('content', meta.get('text', ''))
                if not doc_content:
                    # å¦‚æœæ²¡æœ‰å†…å®¹ï¼Œä½¿ç”¨å…ƒæ•°æ®ä¿¡æ¯ä½œä¸ºæ–‡æ¡£
                    doc_content = f"Document {i}: {meta.get('title', 'Untitled')}"
                
                documents.append(doc_content)
                metadatas.append(meta)
            
            # æ·»åŠ åˆ°ChromaDB
            self.vector_db.add_documents(
                documents=documents,
                metadatas=metadatas,
                embeddings=vectors.tolist()
            )
            
            logger.info(f"Added {len(vectors)} vectors to ChromaDB")
            
        except Exception as e:
            logger.error(f"Error adding vectors to database: {e}")
            raise
    
    def search_similar_vectors(self, query_vector: np.ndarray, top_k: int = 10) -> tuple:
        """
        åœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢ç›¸ä¼¼å‘é‡
        
        Args:
            query_vector: æŸ¥è¯¢å‘é‡
            top_k: è¿”å›å‰kä¸ªæœ€ç›¸ä¼¼çš„å‘é‡
            
        Returns:
            (ç›¸ä¼¼åº¦åˆ†æ•°, ç´¢å¼•)
        """
        try:
            # æ£€æŸ¥ChromaDBæ˜¯å¦æœ‰æ•°æ®
            if self.vector_db._collection.count() == 0:
                return np.array([]), np.array([])
            
            # ç¡®ä¿æŸ¥è¯¢å‘é‡æ˜¯äºŒç»´çš„
            if query_vector.ndim == 1:
                query_vector = query_vector.reshape(1, -1)
            
            # ä½¿ç”¨ChromaDBçš„ç›¸ä¼¼åº¦æœç´¢
            results = self.vector_db.similarity_search_with_score_by_vector(
                embedding=query_vector[0].tolist(),
                k=top_k
            )
            
            # æå–åˆ†æ•°å’Œç´¢å¼•
            scores = np.array([result[1] for result in results])
            indices = np.array([i for i in range(len(results))])
            
            return scores, indices
            
        except Exception as e:
            logger.error(f"Error searching similar vectors: {e}")
            return np.array([]), np.array([])
    
    def save_vector_db(self, db_path: str):
        """
        ä¿å­˜å‘é‡æ•°æ®åº“
        
        Args:
            db_path: æ•°æ®åº“ä¿å­˜è·¯å¾„
        """
        try:
            # ChromaDBä¼šè‡ªåŠ¨æŒä¹…åŒ–ï¼Œè¿™é‡Œåªéœ€è¦ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(db_path, exist_ok=True)
            logger.info(f"ChromaDB vector database persisted to {db_path}")
            
        except Exception as e:
            logger.error(f"Error saving vector database: {e}")
            raise
    
    def load_vector_db(self, db_path: str):
        """
        åŠ è½½å‘é‡æ•°æ®åº“
        
        Args:
            db_path: æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        try:
            if os.path.exists(db_path):
                # ChromaDBä¼šè‡ªåŠ¨ä»æŒä¹…åŒ–ç›®å½•åŠ è½½
                from langchain_chroma import Chroma
                from langchain_community.embeddings import HuggingFaceEmbeddings
                
                self.embedding_function = HuggingFaceEmbeddings(
                    model_name=self.model_name,
                    model_kwargs={'device': 'cpu'},
                    encode_kwargs={'normalize_embeddings': True}
                )
                
                self.vector_db = Chroma(
                    persist_directory=db_path,
                    embedding_function=self.embedding_function,
                    collection_name="knowledge_retrieval"
                )
                logger.info(f"ChromaDB vector database loaded from {db_path}")
            else:
                logger.warning(f"Vector database directory not found: {db_path}")
                
        except Exception as e:
            logger.error(f"Error loading vector database: {e}")
            raise
    
    def get_db_stats(self) -> Dict[str, Any]:
        """
        è·å–å‘é‡æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            return {
                'total_vectors': self.vector_db._collection.count(),
                'vector_dimension': self.vector_dim,
                'collection_name': 'knowledge_retrieval',
                'persist_directory': self.db_path
            }
        except Exception as e:
            logger.error(f"Error getting database stats: {e}")
            return {}
    
    def clear_db(self):
        """æ¸…ç©ºå‘é‡æ•°æ®åº“"""
        try:
            # ChromaDBçš„resetæ–¹æ³•ä¼šæ¸…ç©ºé›†åˆ
            self.vector_db._collection.delete()
            logger.info("ChromaDB vector database cleared")
        except Exception as e:
            logger.error(f"Error clearing database: {e}")
            raise
    
    def chunk_document(self, text: str, metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """
        åˆ‡åˆ†æ–‡æ¡£
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            metadata: æ–‡æ¡£å…ƒæ•°æ®
            
        Returns:
            åˆ‡åˆ†åçš„æ–‡æ¡£ç‰‡æ®µåˆ—è¡¨
        """
        try:
            if self.document_chunker:
                return self.document_chunker.chunk_document(text, metadata)
            else:
                # å¤‡ç”¨æ–¹æ¡ˆï¼šç®€å•åˆ‡åˆ†
                return self._simple_chunking(text, metadata)
        except Exception as e:
            logger.error(f"æ–‡æ¡£åˆ‡åˆ†å¤±è´¥: {e}")
            return []
    
    def _simple_chunking(self, text: str, metadata: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """ç®€å•æ–‡æ¡£åˆ‡åˆ†ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰"""
        chunk_size = 512
        overlap = 50
        chunks = []
        
        start = 0
        chunk_index = 0
        
        while start < len(text):
            end = start + chunk_size
            if end >= len(text):
                chunk_text = text[start:]
            else:
                chunk_text = text[start:end]
            
            if len(chunk_text.strip()) > 100:  # æœ€å°é•¿åº¦è¿‡æ»¤
                chunk_data = {
                    'id': f"chunk_{chunk_index}",
                    'content': chunk_text.strip(),
                    'length': len(chunk_text),
                    'chunk_index': chunk_index,
                    'metadata': metadata or {}
                }
                chunks.append(chunk_data)
                chunk_index += 1
            
            start = end - overlap
            if start >= len(text):
                break
        
        return chunks
    
    def process_document_with_chunking(self, text: str, metadata: Dict[str, Any] = None) -> Dict[str, Any]:
        """
        å¤„ç†æ–‡æ¡£ï¼ˆåŒ…å«åˆ‡åˆ†å’Œå‘é‡åŒ–ï¼‰
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            metadata: æ–‡æ¡£å…ƒæ•°æ®
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            # 1. æ–‡æ¡£åˆ‡åˆ†
            chunks = self.chunk_document(text, metadata)
            
            if not chunks:
                return {'chunks': [], 'vectors': [], 'error': 'æ–‡æ¡£åˆ‡åˆ†å¤±è´¥'}
            
            # 2. æå–æ–‡æœ¬å†…å®¹
            chunk_texts = [chunk['content'] for chunk in chunks]
            
            # 3. å‘é‡åŒ–
            vectors = self.batch_text_to_vectors(chunk_texts)
            
            # 4. ç»„åˆç»“æœ
            result = {
                'chunks': chunks,
                'vectors': vectors,
                'total_chunks': len(chunks),
                'vector_dimension': vectors.shape[1] if len(vectors) > 0 else 0
            }
            
            return result
            
        except Exception as e:
            logger.error(f"æ–‡æ¡£å¤„ç†å¤±è´¥: {e}")
            return {'chunks': [], 'vectors': [], 'error': str(e)}


class VectorServiceFactory:
    """å‘é‡åŒ–æœåŠ¡å·¥å‚ç±»"""
    
    @staticmethod
    def create_vector_service(config_path: str = None) -> VectorService:
        """
        åˆ›å»ºå‘é‡åŒ–æœåŠ¡å®ä¾‹
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾„
            
        Returns:
            å‘é‡åŒ–æœåŠ¡å®ä¾‹
        """
        # é»˜è®¤é…ç½®
        try:
            import torch
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
        except ImportError:
            device = 'cpu'
            
        default_config = {
            'device': device,
            'vector_dim': 768,  # text2vec-base-chineseçš„å‘é‡ç»´åº¦
            'batch_size': 32,
            'text_model_path': 'shibing624/text2vec-base-chinese',
            'image_model_path': 'clip-ViT-B-32'
        }
        
        # å¦‚æœæä¾›äº†é…ç½®æ–‡ä»¶ï¼Œåˆ™åŠ è½½é…ç½®
        if config_path and os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                default_config.update(user_config)
            except Exception as e:
                logger.warning(f"Error loading config file: {e}, using default config")
        
        return VectorService(default_config)


if __name__ == "__main__":
    # æµ‹è¯•å‘é‡åŒ–æœåŠ¡
    config = {
        'device': 'cpu',
        'vector_dim': 768,  # text2vec-base-chineseçš„å‘é‡ç»´åº¦
        'batch_size': 16
    }
    
    vector_service = VectorService(config)
    
    # æµ‹è¯•æ–‡æœ¬å‘é‡åŒ–
    test_text = "æ‚£è€…å‡ºç°èƒ¸ç—›ç—‡çŠ¶ï¼ŒæŒç»­3å°æ—¶ï¼Œä¼´æœ‰å‘¼å¸å›°éš¾"
    vector = vector_service.text_to_vector(test_text)
    print(f"Text vector shape: {vector.shape}")
    
    # æµ‹è¯•æ‰¹é‡æ–‡æœ¬å‘é‡åŒ–
    test_texts = [
        "æ‚£è€…å‡ºç°èƒ¸ç—›ç—‡çŠ¶",
        "æ‚£è€…å‡ºç°å‘¼å¸å›°éš¾",
        "æ‚£è€…å‡ºç°å‘çƒ­ç—‡çŠ¶"
    ]
    vectors = vector_service.batch_text_to_vectors(test_texts)
    print(f"Batch text vectors shape: {vectors.shape}")
    
    # æµ‹è¯•å‘é‡æ•°æ®åº“
    metadata = [{"text": text, "id": i} for i, text in enumerate(test_texts)]
    vector_service.add_vectors_to_db(vectors, metadata)
    
    # æµ‹è¯•æœç´¢
    query_vector = vector_service.text_to_vector("èƒ¸ç—›")
    scores, indices = vector_service.search_similar_vectors(query_vector, top_k=2)
    print(f"Search results - scores: {scores}, indices: {indices}")
    
    # è·å–æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
    stats = vector_service.get_db_stats()
    print(f"Database stats: {stats}")
