#!/usr/bin/env python3
"""
åŒ»ç–—çŸ¥è¯†å‘é‡åŒ–æ‰§è¡Œè„šæœ¬
ç”¨äºå°†åŒ»ç–—æ–‡æœ¬å’Œå›¾åƒæ•°æ®è½¬æ¢ä¸ºå‘é‡å¹¶å­˜å‚¨åˆ°å‘é‡æ•°æ®åº“ä¸­

ä½¿ç”¨æ–¹æ³•:
python run_vectorization.py [é€‰é¡¹]

é€‰é¡¹:
  --mode {check,text,image,multimodal,all,test}  é€‰æ‹©æ‰§è¡Œæ¨¡å¼
  --skip-check                                   è·³è¿‡æ•°æ®æ–‡ä»¶æ£€æŸ¥
  --config CONFIG_PATH                           æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„

æ•°æ®ç›®å½•ç»“æ„:
datas/medical_knowledge/
â”œâ”€â”€ text_data/raw/          # æ”¾ç½®æ–‡æœ¬æ•°æ®æ–‡ä»¶
â”œâ”€â”€ image_text_data/raw/    # æ”¾ç½®å›¾åƒæ•°æ®æ–‡ä»¶
â””â”€â”€ vector_databases/       # å‘é‡æ•°æ®åº“å­˜å‚¨ä½ç½®
"""

import os
import sys
import json
import argparse
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
current_dir = Path(__file__).parent
sys.path.append(str(current_dir))
sys.path.append(str(current_dir / "core"))

def check_data_files():
    """æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print("=== æ£€æŸ¥æ•°æ®æ–‡ä»¶ ===")
    
    # æ•°æ®ç›®å½•è·¯å¾„
    base_data_dir = Path("/Users/tiangels/AI/llm_learning_project/zhi_zhen_tong_system/datas/medical_knowledge")
    
    # æ£€æŸ¥æ–‡æœ¬æ•°æ®
    text_raw_dir = base_data_dir / "text_data" / "raw"
    print(f"æ–‡æœ¬æ•°æ®ç›®å½•: {text_raw_dir}")
    if text_raw_dir.exists():
        text_files = list(text_raw_dir.glob("*"))
        print(f"  âœ… æ‰¾åˆ° {len(text_files)} ä¸ªæ–‡æœ¬æ–‡ä»¶")
        if text_files:
            print("  ç¤ºä¾‹æ–‡ä»¶:")
            for file in text_files[:3]:
                print(f"    - {file.name}")
    else:
        print("  âŒ æ–‡æœ¬æ•°æ®ç›®å½•ä¸å­˜åœ¨")
        return False
    
    # æ£€æŸ¥å›¾åƒæ•°æ®
    image_raw_dir = base_data_dir / "image_text_data" / "raw"
    print(f"å›¾åƒæ•°æ®ç›®å½•: {image_raw_dir}")
    if image_raw_dir.exists():
        image_files = list(image_raw_dir.rglob("*.png")) + list(image_raw_dir.rglob("*.jpg")) + list(image_raw_dir.rglob("*.jpeg"))
        print(f"  âœ… æ‰¾åˆ° {len(image_files)} ä¸ªå›¾åƒæ–‡ä»¶")
        if image_files:
            print("  ç¤ºä¾‹æ–‡ä»¶:")
            for file in image_files[:3]:
                print(f"    - {file.relative_to(image_raw_dir)}")
    else:
        print("  âŒ å›¾åƒæ•°æ®ç›®å½•ä¸å­˜åœ¨")
        return False
    
    # æ£€æŸ¥åŸå§‹æŠ¥å‘Šæ–‡ä»¶
    raw_reports = base_data_dir / "image_text_data" / "raw" / "chestX-rays" / "indiana_reports.csv"
    print(f"\nåŸå§‹æ•°æ®æ£€æŸ¥:")
    print(f"  æŠ¥å‘Šæ–‡ä»¶: {'âœ… å­˜åœ¨' if raw_reports.exists() else 'âŒ ä¸å­˜åœ¨'}")
    
    # æ£€æŸ¥å¤„ç†åçš„æ•°æ®
    processed_reports = base_data_dir / "image_text_data" / "processed" / "processed_reports.csv"
    processed_images = base_data_dir / "image_text_data" / "processed" / "processed_images.npy"
    
    # æ£€æŸ¥çº¯æ–‡æœ¬å¤„ç†åçš„æ•°æ®
    general_text_train = base_data_dir / "text_data" / "processed" / "training_data" / "general_text_train.csv"
    general_text_test = base_data_dir / "text_data" / "processed" / "test_data" / "general_text_test.csv"
    
    print(f"\nå¤„ç†åæ•°æ®æ£€æŸ¥:")
    print(f"  æŠ¥å‘Šæ–‡ä»¶: {'âœ… å­˜åœ¨' if processed_reports.exists() else 'âš ï¸  ä¸å­˜åœ¨ï¼Œéœ€è¦é¢„å¤„ç†'}")
    print(f"  å›¾åƒæ–‡ä»¶: {'âœ… å­˜åœ¨' if processed_images.exists() else 'âš ï¸  ä¸å­˜åœ¨ï¼Œéœ€è¦é¢„å¤„ç†'}")
    print(f"  çº¯æ–‡æœ¬è®­ç»ƒæ•°æ®: {'âœ… å­˜åœ¨' if general_text_train.exists() else 'âš ï¸  ä¸å­˜åœ¨ï¼Œéœ€è¦é¢„å¤„ç†'}")
    print(f"  çº¯æ–‡æœ¬æµ‹è¯•æ•°æ®: {'âœ… å­˜åœ¨' if general_text_test.exists() else 'âš ï¸  ä¸å­˜åœ¨ï¼Œéœ€è¦é¢„å¤„ç†'}")
    
    return True

def run_data_preprocessing():
    """è¿è¡Œæ•°æ®é¢„å¤„ç†"""
    print("\n=== å¼€å§‹æ•°æ®é¢„å¤„ç† ===")
    print("æ•°æ®æµç¨‹: rawæ•°æ® â†’ é¢„å¤„ç† â†’ processedæ•°æ®")
    
    try:
        # å¯¼å…¥é¢„å¤„ç†æ¨¡å—
        sys.path.append(str(current_dir / "processors"))
        from text_preprocessing import OptimizedMedicalTextPreprocessor
        from image_text_preprocessing import MedicalImageTextPreprocessor
        
        success = True
        
        # æ–‡æœ¬æ•°æ®é¢„å¤„ç†
        print("\n--- æ–‡æœ¬æ•°æ®é¢„å¤„ç† ---")
        try:
            # å¤„ç†é€šç”¨æ–‡æœ¬æ•°æ®ï¼ˆPDFã€TXTã€CSVç­‰ï¼‰
            raw_data_dir = "/Users/tiangels/AI/llm_learning_project/zhi_zhen_tong_system/datas/medical_knowledge/text_data/raw"
            output_dir = "/Users/tiangels/AI/llm_learning_project/zhi_zhen_tong_system/datas/medical_knowledge/text_data/processed"
            
            from general_text_preprocessing import GeneralTextPreprocessor
            general_text_preprocessor = GeneralTextPreprocessor(raw_data_dir, output_dir)
            general_text_preprocessor.run()
            print("âœ… é€šç”¨æ–‡æœ¬æ•°æ®é¢„å¤„ç†å®Œæˆ")
            
            # å¤„ç†ç‰¹å®šæ ¼å¼çš„åŒ»ç–—å¯¹è¯æ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            try:
                text_preprocessor = OptimizedMedicalTextPreprocessor(raw_data_dir, output_dir)
                text_preprocessor.run(sample_size=100)  # å¤„ç†æ‰€æœ‰æ•°æ®
                print("âœ… åŒ»ç–—å¯¹è¯æ•°æ®é¢„å¤„ç†å®Œæˆ")
            except Exception as e:
                print(f"âš ï¸  åŒ»ç–—å¯¹è¯æ•°æ®é¢„å¤„ç†è·³è¿‡: {e}")
                
        except Exception as e:
            print(f"âŒ æ–‡æœ¬æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            success = False
        
        # å›¾åƒæ•°æ®é¢„å¤„ç†
        print("\n--- å›¾åƒæ•°æ®é¢„å¤„ç† ---")
        try:
            data_dir = "/Users/tiangels/AI/llm_learning_project/zhi_zhen_tong_system/datas/medical_knowledge/image_text_data/raw"
            
            image_preprocessor = MedicalImageTextPreprocessor(data_dir)
            image_preprocessor.run()
            print("âœ… å›¾åƒæ•°æ®é¢„å¤„ç†å®Œæˆ")
        except Exception as e:
            print(f"âŒ å›¾åƒæ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
            success = False
        
        if success:
            print("\nâœ… æ•°æ®é¢„å¤„ç†å®Œæˆ")
            print("ç°åœ¨å¯ä»¥ç»§ç»­è¿›è¡Œå‘é‡åŒ–...")
        
        return success
        
    except Exception as e:
        print(f"âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥: {e}")
        return False

def run_text_vectorization():
    """è¿è¡Œæ–‡æœ¬å‘é‡åŒ–"""
    print("\n=== å¼€å§‹æ–‡æœ¬å‘é‡åŒ– ===")
    
    try:
        from core.build_multimodal_database import UnifiedMultimodalVectorDatabaseBuilder
        
        # åˆå§‹åŒ–æ„å»ºå™¨
        builder = UnifiedMultimodalVectorDatabaseBuilder()
        
        # åªæ„å»ºæ–‡æœ¬å‘é‡æ•°æ®åº“ï¼ˆå·²æ³¨é‡Š - ç°åœ¨åªæ„å»ºå¤šæ¨¡æ€æ•°æ®åº“ï¼‰
        # builder.build_database(
        #     build_text=True,
        #     build_image=False,
        #     build_multimodal=False
        # )
        print("âš ï¸  æ–‡æœ¬å‘é‡åŒ–æ¨¡å¼å·²ç¦ç”¨ï¼Œç°åœ¨ç»Ÿä¸€ä½¿ç”¨å¤šæ¨¡æ€æ•°æ®åº“")
        return False
        
        print("âœ… æ–‡æœ¬å‘é‡åŒ–å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ æ–‡æœ¬å‘é‡åŒ–å¤±è´¥: {e}")
        return False

def run_image_vectorization():
    """è¿è¡Œå›¾åƒå‘é‡åŒ–"""
    print("\n=== å¼€å§‹å›¾åƒå‘é‡åŒ– ===")
    
    try:
        from core.build_multimodal_database import UnifiedMultimodalVectorDatabaseBuilder
        
        # åˆå§‹åŒ–æ„å»ºå™¨
        builder = UnifiedMultimodalVectorDatabaseBuilder()
        
        # åªæ„å»ºå›¾åƒå‘é‡æ•°æ®åº“ï¼ˆå·²æ³¨é‡Š - ç°åœ¨åªæ„å»ºå¤šæ¨¡æ€æ•°æ®åº“ï¼‰
        # builder.build_database(
        #     build_text=False,
        #     build_image=True,
        #     build_multimodal=False
        # )
        print("âš ï¸  å›¾åƒå‘é‡åŒ–æ¨¡å¼å·²ç¦ç”¨ï¼Œç°åœ¨ç»Ÿä¸€ä½¿ç”¨å¤šæ¨¡æ€æ•°æ®åº“")
        return False
        
        print("âœ… å›¾åƒå‘é‡åŒ–å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ å›¾åƒå‘é‡åŒ–å¤±è´¥: {e}")
        return False

def run_multimodal_vectorization():
    """è¿è¡Œå¤šæ¨¡æ€å‘é‡åŒ–ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰"""
    print("\n=== å¼€å§‹å¤šæ¨¡æ€å‘é‡åŒ– ===")
    print("è¿™æ˜¯å¤šæ¨¡æ€å‘é‡åŒ–çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œå°†æ„å»º:")
    print("1. å¤šæ¨¡æ€å‘é‡æ•°æ®åº“ï¼ˆç»Ÿä¸€å¤„ç†æ–‡æœ¬å’Œå›¾åƒï¼‰")
    print("2. å›¾åƒ-æ–‡æœ¬æ˜ å°„å…³ç³»")
    print("3. ä¼˜åŒ–è¯´æ˜: å·²ç§»é™¤å†—ä½™çš„å•ç‹¬æ•°æ®åº“ï¼Œæé«˜æ„å»ºæ•ˆç‡")
    
    try:
        from core.build_multimodal_database import UnifiedMultimodalVectorDatabaseBuilder
        
        # åˆå§‹åŒ–æ„å»ºå™¨
        builder = UnifiedMultimodalVectorDatabaseBuilder()
        
        # æ„å»ºå¤šæ¨¡æ€å‘é‡æ•°æ®åº“ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ - åªæ„å»ºå¤šæ¨¡æ€æ•°æ®åº“ï¼‰
        builder.build_database(
            build_multimodal=True  # åªæ„å»ºå¤šæ¨¡æ€å‘é‡æ•°æ®åº“
        )
        
        print("âœ… å¤šæ¨¡æ€å‘é‡åŒ–å®Œæˆ")
        print("\nğŸ“Š æ„å»ºç»“æœ:")
        print("  - å¤šæ¨¡æ€å‘é‡æ•°æ®åº“: ç»Ÿä¸€å¤„ç†æ–‡æœ¬å’Œå›¾åƒæ£€ç´¢")
        print("  - å›¾åƒ-æ–‡æœ¬æ˜ å°„: æ”¯æŒå›¾æ–‡é…å¯¹æ£€ç´¢")
        print("  - ä¼˜åŒ–è¯´æ˜: å·²ç§»é™¤å†—ä½™çš„å•ç‹¬æ•°æ®åº“ï¼Œæé«˜æ•ˆç‡")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤šæ¨¡æ€å‘é‡åŒ–å¤±è´¥: {e}")
        print("\nğŸ”§ æ•…éšœæ’é™¤å»ºè®®:")
        print("1. æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨")
        print("2. æ£€æŸ¥æ¨¡å‹ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…")
        print("3. æ£€æŸ¥å†…å­˜æ˜¯å¦å……è¶³")
        print("4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯æ—¥å¿—")
        return False

def run_unified_multimodal_retrieval_test():
    """è¿è¡Œç»Ÿä¸€å¤šæ¨¡æ€æ£€ç´¢æµ‹è¯•"""
    print("\n=== æµ‹è¯•ç»Ÿä¸€å¤šæ¨¡æ€æ£€ç´¢ç³»ç»Ÿ ===")
    
    try:
        from core.build_multimodal_database import UnifiedMultimodalRetrieval
        
        # åˆå§‹åŒ–ç»Ÿä¸€æ£€ç´¢ç³»ç»Ÿ
        retrieval_system = UnifiedMultimodalRetrieval()
        
        # æµ‹è¯•æ–‡æœ¬æ£€ç´¢
        print("æµ‹è¯•æ–‡æœ¬æ£€ç´¢...")
        query = "å³çœ¼æµçœ¼æ³ª"
        results = retrieval_system.search(query=query, top_k=3)
        
        print(f"æŸ¥è¯¢: {query}")
        print(f"æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³ç»“æœ")
        for i, result in enumerate(results, 1):
            print(f"ç»“æœ {i}: ç›¸ä¼¼åº¦={result['similarity_score']:.4f}")
            print(f"  å†…å®¹: {result['content'][:100]}...")
            print(f"  UID: {result['uid']}")
            print(f"  ç±»å‹: {result['content_type']}")
        
        # æµ‹è¯•å›¾åƒæ£€ç´¢ï¼ˆå¦‚æœæœ‰æµ‹è¯•å›¾åƒï¼‰
        print("\næµ‹è¯•å›¾åƒæ£€ç´¢...")
        test_image_path = "/Users/tiangels/AI/llm_learning_project/zhi_zhen_tong_system/datas/medical_knowledge/image_text_data/raw/chestX-rays/images"
        if os.path.exists(test_image_path):
            image_files = [f for f in os.listdir(test_image_path) if f.endswith(('.png', '.jpg', '.jpeg'))]
            if image_files:
                test_image = os.path.join(test_image_path, image_files[0])
                print(f"ä½¿ç”¨æµ‹è¯•å›¾åƒ: {test_image}")
                image_results = retrieval_system.search(image_path=test_image, top_k=3)
                
                print(f"å›¾åƒæ£€ç´¢æ‰¾åˆ° {len(image_results)} ä¸ªç›¸å…³ç»“æœ")
                for i, result in enumerate(image_results, 1):
                    print(f"ç»“æœ {i}: ç›¸ä¼¼åº¦={result['similarity_score']:.4f}")
                    print(f"  å†…å®¹: {result['content'][:100]}...")
                    print(f"  UID: {result['uid']}")
                    print(f"  ç±»å‹: {result['content_type']}")
            else:
                print("æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒæ–‡ä»¶")
        else:
            print("æµ‹è¯•å›¾åƒç›®å½•ä¸å­˜åœ¨")
        
        print("âœ… ç»Ÿä¸€å¤šæ¨¡æ€æ£€ç´¢ç³»ç»Ÿæµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        print(f"âŒ ç»Ÿä¸€å¤šæ¨¡æ€æ£€ç´¢æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="åŒ»ç–—çŸ¥è¯†å‘é‡åŒ–æ‰§è¡Œè„šæœ¬",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # æ£€æŸ¥æ•°æ®æ–‡ä»¶
  python run_vectorization.py --check-data
  python run_vectorization.py --mode check
  
  # åªè¿›è¡Œæ•°æ®é¢„å¤„ç†
  python run_vectorization.py --preprocess
  python run_vectorization.py --mode preprocess
  
  # åªæ„å»ºæ–‡æœ¬å‘é‡æ•°æ®åº“
  python run_vectorization.py --text
  python run_vectorization.py --mode text
  
  # åªæ„å»ºå›¾åƒå‘é‡æ•°æ®åº“
  python run_vectorization.py --image
  python run_vectorization.py --mode image
  
  # åªæ„å»ºå¤šæ¨¡æ€å‘é‡æ•°æ®åº“ï¼ˆæ¨èç”¨äºç”Ÿäº§ï¼‰
  python run_vectorization.py --multimodal
  python run_vectorization.py --mode multimodal
  
  # å®Œæ•´æµç¨‹ï¼šé¢„å¤„ç† + æ„å»ºæ‰€æœ‰ç±»å‹çš„å‘é‡æ•°æ®åº“ï¼ˆæ¨èï¼‰
  python run_vectorization.py --all
  python run_vectorization.py --mode all
  
  # æµ‹è¯•è·¨æ¨¡æ€æ£€ç´¢ç³»ç»Ÿ
  python run_vectorization.py --test
  python run_vectorization.py --mode test
  
  # è·³è¿‡æ£€æŸ¥ï¼Œç›´æ¥æ„å»ºï¼ˆçº¿ä¸Šç¯å¢ƒæ¨èï¼‰
  python run_vectorization.py --multimodal --skip-check
        """
    )
    
    parser.add_argument("--mode", 
                       choices=["check", "preprocess", "text", "image", "multimodal", "all", "test"], 
                       default="all", 
                       help="æ‰§è¡Œæ¨¡å¼ (é»˜è®¤: all)")
    
    # æ·»åŠ ä¾¿æ·å‚æ•°
    parser.add_argument("--check-data", 
                       action="store_true", 
                       help="æ£€æŸ¥æ•°æ®æ–‡ä»¶")
    parser.add_argument("--preprocess", 
                       action="store_true", 
                       help="åªè¿›è¡Œæ•°æ®é¢„å¤„ç†")
    parser.add_argument("--text", 
                       action="store_true", 
                       help="åªæ„å»ºæ–‡æœ¬å‘é‡æ•°æ®åº“")
    parser.add_argument("--image", 
                       action="store_true", 
                       help="åªæ„å»ºå›¾åƒå‘é‡æ•°æ®åº“")
    parser.add_argument("--multimodal", 
                       action="store_true", 
                       help="åªæ„å»ºå¤šæ¨¡æ€å‘é‡æ•°æ®åº“")
    parser.add_argument("--test", 
                       action="store_true", 
                       help="æµ‹è¯•è·¨æ¨¡æ€æ£€ç´¢ç³»ç»Ÿ")
    parser.add_argument("--all", 
                       action="store_true", 
                       help="æ„å»ºæ‰€æœ‰ç±»å‹çš„å‘é‡æ•°æ®åº“")
    
    parser.add_argument("--skip-check", 
                       action="store_true", 
                       help="è·³è¿‡æ•°æ®æ–‡ä»¶æ£€æŸ¥")
    parser.add_argument("--config", 
                       type=str, 
                       help="æŒ‡å®šé…ç½®æ–‡ä»¶è·¯å¾„")
    
    args = parser.parse_args()
    
    print("ğŸ¥ åŒ»ç–—çŸ¥è¯†å‘é‡åŒ–ç³»ç»Ÿ")
    print("=" * 50)
    
    # å¤„ç†ä¾¿æ·å‚æ•°ï¼Œç¡®å®šæ‰§è¡Œæ¨¡å¼
    mode = args.mode
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ä¾¿æ·å‚æ•°è¢«ä½¿ç”¨
    convenience_args = [args.check_data, args.preprocess, args.text, args.image, args.multimodal, args.test, args.all]
    if any(convenience_args):
        if args.check_data:
            mode = "check"
        elif args.preprocess:
            mode = "preprocess"
        elif args.text:
            mode = "text"
        elif args.image:
            mode = "image"
        elif args.multimodal:
            mode = "multimodal"
        elif args.test:
            mode = "test"
        elif args.all:
            mode = "all"
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶
    if not args.skip_check and mode != "check":
        if not check_data_files():
            print("âŒ æ•°æ®æ–‡ä»¶æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®ç›®å½•")
            return 1
    
    success = True
    
    if mode == "check":
        if not check_data_files():
            success = False
        if success:
            print("\nâœ… æ•°æ®æ–‡ä»¶æ£€æŸ¥å®Œæˆ")
        return 0 if success else 1
    
    elif mode == "preprocess":
        if not run_data_preprocessing():
            success = False
    
    elif mode == "text":
        if not run_text_vectorization():
            success = False
    
    elif mode == "image":
        if not run_image_vectorization():
            success = False
    
    elif mode == "multimodal":
        if not run_multimodal_vectorization():
            success = False
    
    elif mode == "all":
        # å®Œæ•´çš„å¤„ç†æµç¨‹ï¼šé¢„å¤„ç† â†’ å‘é‡åŒ–
        print("\nğŸ”„ æ‰§è¡Œå®Œæ•´å¤„ç†æµç¨‹ï¼šé¢„å¤„ç† â†’ å‘é‡åŒ–")
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦éœ€è¦é¢„å¤„ç†
        base_data_dir = Path("/Users/tiangels/AI/llm_learning_project/zhi_zhen_tong_system/datas/medical_knowledge")
        processed_reports = base_data_dir / "image_text_data" / "processed" / "processed_reports.csv"
        processed_images = base_data_dir / "image_text_data" / "processed" / "processed_images.npy"
        general_text_train = base_data_dir / "text_data" / "processed" / "training_data" / "general_text_train.csv"
        general_text_test = base_data_dir / "text_data" / "processed" / "test_data" / "general_text_test.csv"
        
        # æ£€æŸ¥æ‰€æœ‰ç±»å‹çš„é¢„å¤„ç†æ•°æ®
        needs_preprocessing = (
            not processed_reports.exists() or 
            not processed_images.exists() or
            not general_text_train.exists() or
            not general_text_test.exists()
        )
        
        if needs_preprocessing:
            print("âš ï¸  æ£€æµ‹åˆ°ç¼ºå°‘é¢„å¤„ç†æ•°æ®ï¼Œå…ˆè¿›è¡Œæ•°æ®é¢„å¤„ç†...")
            if not run_data_preprocessing():
                success = False
                print("âŒ æ•°æ®é¢„å¤„ç†å¤±è´¥ï¼Œæ— æ³•ç»§ç»­å‘é‡åŒ–")
            else:
                print("âœ… æ•°æ®é¢„å¤„ç†å®Œæˆï¼Œå¼€å§‹å‘é‡åŒ–...")
        else:
            print("âœ… é¢„å¤„ç†æ•°æ®å·²å­˜åœ¨ï¼Œç›´æ¥è¿›è¡Œå‘é‡åŒ–...")
        
        # å¦‚æœé¢„å¤„ç†æˆåŠŸæˆ–ä¸éœ€è¦é¢„å¤„ç†ï¼Œç»§ç»­å‘é‡åŒ–
        if success:
            # åªæ‰§è¡Œå¤šæ¨¡æ€å‘é‡åŒ–ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
            print("\nğŸ’¡ ä¼˜åŒ–è¯´æ˜: å·²ç§»é™¤å†—ä½™çš„å•ç‹¬æ•°æ®åº“æ„å»ºï¼Œç°åœ¨åªæ„å»ºå¤šæ¨¡æ€æ•°æ®åº“")
            if not run_multimodal_vectorization():
                success = False
    
    elif mode == "test":
        if not run_unified_multimodal_retrieval_test():
            success = False
    
    if success:
        print("\nğŸ‰ å‘é‡åŒ–ä»»åŠ¡æ‰§è¡ŒæˆåŠŸï¼")
        print("\nğŸ“ å‘é‡æ•°æ®åº“ä½ç½®:")
        base_data_dir = Path("/Users/tiangels/AI/llm_learning_project/zhi_zhen_tong_system/datas/medical_knowledge")
        print(f"  å¤šæ¨¡æ€å‘é‡æ•°æ®åº“: {Path('/Users/tiangels/AI/llm_learning_project/zhi_zhen_tong_system/datas') / 'vector_databases' / 'multimodal'}")
        print(f"  å›¾åƒ-æ–‡æœ¬æ˜ å°„: {Path('/Users/tiangels/AI/llm_learning_project/zhi_zhen_tong_system/datas') / 'vector_databases' / 'multimodal' / 'image_text_mapping.json'}")
        print("\nğŸ’¡ ä¼˜åŒ–è¯´æ˜:")
        print("   - å·²ç§»é™¤å†—ä½™çš„å•ç‹¬æ–‡æœ¬å’Œå›¾åƒå‘é‡æ•°æ®åº“")
        print("   - ç°åœ¨ç»Ÿä¸€ä½¿ç”¨å¤šæ¨¡æ€å‘é‡æ•°æ®åº“ï¼Œæé«˜æ•ˆç‡")
        print("   - æ”¯æŒæ–‡æœ¬å’Œå›¾åƒçš„è·¨æ¨¡æ€æ£€ç´¢")
        
        print("\nğŸš€ ç°åœ¨æ‚¨å¯ä»¥ä½¿ç”¨è·¨æ¨¡æ€æ£€ç´¢ç³»ç»Ÿäº†ï¼")
        print("   - é€šè¿‡æ–‡æœ¬æŸ¥è¯¢ç›¸å…³å›¾åƒ")
        print("   - é€šè¿‡å›¾åƒæŸ¥è¯¢ç›¸å…³æ–‡æœ¬")
        print("   - æ”¯æŒå›¾æ–‡é…å¯¹æ£€ç´¢")
        
        return 0
    else:
        print("\nâŒ éƒ¨åˆ†ä»»åŠ¡æ‰§è¡Œå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        return 1

if __name__ == "__main__":
    exit(main())
