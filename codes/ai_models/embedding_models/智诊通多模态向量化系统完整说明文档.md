# æ™ºè¯Šé€šå¤šæ¨¡æ€å‘é‡åŒ–ç³»ç»Ÿå®Œæ•´è¯´æ˜æ–‡æ¡£

## ğŸ“‹ ç³»ç»Ÿæ¦‚è¿°

æ™ºè¯Šé€šå¤šæ¨¡æ€å‘é‡åŒ–ç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäºRAGï¼ˆRetrieval-Augmented Generationï¼‰æŠ€æœ¯çš„æ™ºèƒ½åŒ»ç–—çŸ¥è¯†æ£€ç´¢å¹³å°ï¼Œæ”¯æŒæ–‡æœ¬ã€å›¾åƒã€è¯­éŸ³ç­‰å¤šç§æ¨¡æ€çš„åŒ»ç–—æ•°æ®å¤„ç†å’Œæ£€ç´¢ã€‚ç³»ç»Ÿé‡‡ç”¨å…ˆè¿›çš„å‘é‡åŒ–æŠ€æœ¯ï¼Œç»“åˆå¤§è¯­è¨€æ¨¡å‹ï¼Œä¸ºåŒ»ç–—é¢†åŸŸæä¾›å‡†ç¡®ã€é«˜æ•ˆçš„æ™ºèƒ½é—®ç­”æœåŠ¡ã€‚

### ğŸ¯ æ ¸å¿ƒç‰¹æ€§

- **å¤šæ¨¡æ€æ”¯æŒ**ï¼šæ–‡æœ¬ã€å›¾åƒã€è¯­éŸ³æ•°æ®çš„ç»Ÿä¸€å¤„ç†
- **è·¨æ¨¡æ€æ£€ç´¢**ï¼šå›¾åƒæŸ¥è¯¢è¿”å›ç›¸å…³æ–‡æœ¬ï¼Œæ–‡æœ¬æŸ¥è¯¢æ”¯æŒå›¾åƒç»“æœ
- **æ™ºèƒ½å‘é‡åŒ–**ï¼šåŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„è¯­ä¹‰å‘é‡è¡¨ç¤º
- **é«˜æ•ˆæ£€ç´¢**ï¼šåŸºäºå‘é‡ç›¸ä¼¼åº¦çš„å¿«é€Ÿæ£€ç´¢
- **ç”Ÿäº§å°±ç»ª**ï¼šå®Œæ•´çš„éƒ¨ç½²é…ç½®å’Œç›‘æ§ä½“ç³»

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ¶æ„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    æ™ºè¯Šé€šå¤šæ¨¡æ€å‘é‡åŒ–ç³»ç»Ÿ                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  å‰ç«¯ç•Œé¢  â”‚  åç«¯API  â”‚  æ£€ç´¢æœåŠ¡  â”‚  å‘é‡åŒ–æœåŠ¡  â”‚  çŸ¥è¯†åº“æ„å»º  â”‚
â”‚  (Vue.js)  â”‚ (FastAPI) â”‚  (RAG)    â”‚ (Vectorization) â”‚ (Building) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    æ•°æ®å­˜å‚¨å±‚        â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚  å‘é‡æ•°æ®åº“     â”‚ â”‚
                    â”‚  â”‚  (ChromaDB)     â”‚ â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
                    â”‚  â”‚  åŸå§‹æ•°æ®       â”‚ â”‚
                    â”‚  â”‚  (åŒ»ç–—æ–‡æ¡£)     â”‚ â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ¨¡å—èŒè´£åˆ†å·¥

| æ¨¡å— | èŒè´£ | æ ¸å¿ƒåŠŸèƒ½ |
|------|------|----------|
| **çŸ¥è¯†åº“æ„å»ºæ¨¡å—** | æ•°æ®å¤„ç†å’Œå‘é‡åŒ– | æ–‡æ¡£åŠ è½½ã€æ¸…æ´—ã€åˆ‡åˆ†ã€å‘é‡åŒ–ã€ç´¢å¼•æ„å»º |
| **æ£€ç´¢æœåŠ¡æ¨¡å—** | æŸ¥è¯¢å¤„ç†å’Œæ£€ç´¢ | é—®é¢˜é¢„å¤„ç†ã€å‘é‡åŒ–ã€æ£€ç´¢ã€é‡æ’åº |
| **å¤šæ¨¡æ€æ£€ç´¢æ¨¡å—** | è·¨æ¨¡æ€æ£€ç´¢ | å›¾åƒåˆ°æ–‡æœ¬æ£€ç´¢ã€æ··åˆæ£€ç´¢ |
| **ç»Ÿä¸€å‘é‡åŒ–æœåŠ¡** | å‘é‡åŒ–å¤„ç† | æ–‡æœ¬ã€å›¾åƒã€è¯­éŸ³å‘é‡åŒ– |
| **å‰ç«¯ç•Œé¢** | ç”¨æˆ·äº¤äº’ | æŸ¥è¯¢è¾“å…¥ã€ç»“æœå±•ç¤ºã€ç³»ç»Ÿç®¡ç† |

---

## ğŸ”„ æ ¸å¿ƒå·¥ä½œæµç¨‹

### 1. çŸ¥è¯†åº“æ„å»ºæµç¨‹

```
åŸå§‹æ•°æ® â†’ æ–‡æ¡£åŠ è½½ â†’ æ•°æ®æ¸…æ´— â†’ æ–‡æ¡£åˆ‡åˆ† â†’ å‘é‡åŒ– â†’ è´¨é‡æ£€æŸ¥ â†’ ç´¢å¼•æ„å»º
   â†“         â†“         â†“         â†“         â†“         â†“         â†“
Word/PDF  å¤šæ ¼å¼    å»é‡/è¿‡æ»¤   Chunk    å‘é‡è¡¨ç¤º   å»é‡/è¿‡æ»¤   å‘é‡æ•°æ®åº“
TXT/Excel æ”¯æŒ      æ ‡å‡†åŒ–     åˆ‡åˆ†      ç”Ÿæˆ      è´¨é‡è¯„ä¼°   ChromaDB
```

#### 1.1 æ–‡æ¡£åŠ è½½ (Document Loading)
- **æ”¯æŒæ ¼å¼**ï¼šWordã€PDFã€TXTã€Excelã€JSONã€å›¾åƒæ–‡ä»¶
- **å®ç°ä½ç½®**ï¼š`processors/data_pipeline.py`
- **æ ¸å¿ƒç±»**ï¼š`DataPipeline`

#### 1.2 æ•°æ®æ¸…æ´— (Data Cleaning)
- **åŠŸèƒ½**ï¼šå»é™¤é‡å¤æ•°æ®ã€æ ‡å‡†åŒ–æ ¼å¼ã€å¤„ç†ç¼ºå¤±å€¼
- **å®ç°ä½ç½®**ï¼š`processors/text_preprocessing.py`
- **æ ¸å¿ƒç±»**ï¼š`OptimizedMedicalTextPreprocessor`

#### 1.3 æ–‡æ¡£åˆ‡åˆ† (Document Chunking) â­
- **åŠŸèƒ½**ï¼šå°†é•¿æ–‡æ¡£åˆ‡åˆ†ä¸ºé€‚åˆå‘é‡åŒ–çš„å°ç‰‡æ®µ
- **å®ç°ä½ç½®**ï¼š`processors/document_chunker.py`
- **æ ¸å¿ƒç±»**ï¼š`DocumentChunker`

**åˆ‡åˆ†ç­–ç•¥**ï¼š
- `FIXED_SIZE`ï¼šå›ºå®šå¤§å°åˆ‡åˆ†
- `SENTENCE_BASED`ï¼šåŸºäºå¥å­åˆ‡åˆ†
- `PARAGRAPH_BASED`ï¼šåŸºäºæ®µè½åˆ‡åˆ†
- `SEMANTIC_BASED`ï¼šåŸºäºè¯­ä¹‰åˆ‡åˆ†
- `MEDICAL_STRUCTURED`ï¼šåŒ»ç–—ç»“æ„åŒ–åˆ‡åˆ† â­

#### 1.4 å‘é‡åŒ– (Vectorization)
- **åŠŸèƒ½**ï¼šå°†æ–‡æœ¬å’Œå›¾åƒè½¬æ¢ä¸ºå‘é‡è¡¨ç¤º
- **å®ç°ä½ç½®**ï¼š`core/vectorization_service.py`
- **æ ¸å¿ƒç±»**ï¼š`VectorizationService`

**å‘é‡åŒ–æ¨¡å‹**ï¼š
- **æ–‡æœ¬æ¨¡å‹**ï¼š`text2vec-base-chinese` (768ç»´)
- **å›¾åƒæ¨¡å‹**ï¼š`openai/clip-vit-base-patch32` (512ç»´)

#### 1.5 è´¨é‡æ£€æŸ¥ (Quality Control)
- **åŠŸèƒ½**ï¼šå‘é‡è´¨é‡è¯„ä¼°ã€å»é‡ã€è¿‡æ»¤
- **å®ç°ä½ç½®**ï¼š`core/data_analyzer.py`
- **æ ¸å¿ƒç±»**ï¼š`MedicalDataAnalyzer`

#### 1.6 ç´¢å¼•æ„å»º (Index Building)
- **åŠŸèƒ½**ï¼šæ„å»ºå‘é‡æ•°æ®åº“ç´¢å¼•
- **å®ç°ä½ç½®**ï¼š`core/build_vector_database.py`
- **æ•°æ®åº“**ï¼šChromaDB

### 2. å¤šæ¨¡æ€æ£€ç´¢æµç¨‹

```
ç”¨æˆ·è¾“å…¥ â†’ é—®é¢˜é¢„å¤„ç† â†’ é—®é¢˜å‘é‡åŒ– â†’ æ£€ç´¢ â†’ é‡æ’åº â†’ ç»“æœè¿”å›
    â†“         â†“           â†“         â†“       â†“         â†“
  å‰ç«¯ç•Œé¢   æ–‡æœ¬æ¸…æ´—    å‘é‡è¡¨ç¤º   ç›¸ä¼¼åº¦   ç»“æœä¼˜åŒ–   æ ¼å¼åŒ–
            æ ‡å‡†åŒ–      ç”Ÿæˆ       æœç´¢     æ’åº      è¾“å‡º
```

#### 2.1 è·¨æ¨¡æ€æ£€ç´¢å®ç°åŸç†

**æ ¸å¿ƒé—®é¢˜**ï¼šå¯¹äºå›¾æ–‡æ•°æ®é›†ï¼Œæ¯å¼ å›¾ç‰‡éƒ½æœ‰å¯¹åº”çš„æ–‡æœ¬è¯´æ˜ï¼Œå½“ç”¨æˆ·è¾“å…¥ä¸€å¼ å›¾ç‰‡æ—¶ï¼Œå¦‚ä½•é€šè¿‡æ£€ç´¢æ‰¾åˆ°ç›¸ä¼¼å›¾ç‰‡å¯¹åº”çš„æ–‡æœ¬è¿”å›ç»™ç”¨æˆ·ï¼Ÿ

**è§£å†³æ–¹æ¡ˆ**ï¼š

1. **å›¾åƒ-æ–‡æœ¬æ˜ å°„å…³ç³»æ„å»º**
```python
def build_image_text_mapping(self, reports_df: pd.DataFrame) -> Dict[str, Dict[str, Any]]:
    """æ„å»ºå›¾åƒå’Œæ–‡æœ¬çš„æ˜ å°„å…³ç³»"""
    mapping = {}
    
    for idx, row in reports_df.iterrows():
        uid = str(row['uid'])
        
        # æ„å»ºæ–‡æœ¬å†…å®¹
        text_parts = []
        if 'findings' in row and pd.notna(row['findings']):
            text_parts.append(f"æ£€æŸ¥ç»“æœ: {row['findings']}")
        if 'impression' in row and pd.notna(row['impression']):
            text_parts.append(f"å°è±¡: {row['impression']}")
        
        if text_parts:
            text_content = "\n".join(text_parts)
            mapping[uid] = {
                'text': text_content,
                'index': idx,
                'metadata': {...}
            }
    
    return mapping
```

2. **åŒå‘é‡å­˜å‚¨ç­–ç•¥**

**ç­–ç•¥Aï¼šå›¾åƒå‘é‡å­˜å‚¨ï¼ˆæ¨èï¼‰**
- å›¾åƒå‘é‡åŒ–ï¼šä½¿ç”¨ResNet50/CLIPç­‰æ¨¡å‹å°†å›¾åƒè½¬æ¢ä¸ºå‘é‡
- å­˜å‚¨æ–¹å¼ï¼šå›¾åƒå‘é‡å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­
- æ£€ç´¢è¿‡ç¨‹ï¼š
  1. ç”¨æˆ·è¾“å…¥å›¾åƒ â†’ å‘é‡åŒ– â†’ åœ¨å›¾åƒå‘é‡åº“ä¸­æœç´¢
  2. æ‰¾åˆ°ç›¸ä¼¼å›¾åƒ â†’ é€šè¿‡æ˜ å°„å…³ç³»è·å–å¯¹åº”æ–‡æœ¬

**ç­–ç•¥Bï¼šæ–‡æœ¬å‘é‡å­˜å‚¨ï¼ˆå¤‡é€‰ï¼‰**
- æ–‡æœ¬å‘é‡åŒ–ï¼šä½¿ç”¨æ–‡æœ¬åµŒå…¥æ¨¡å‹å°†æè¿°æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡
- å­˜å‚¨æ–¹å¼ï¼šæ–‡æœ¬å‘é‡å­˜å‚¨åœ¨å‘é‡æ•°æ®åº“ä¸­

3. **è·¨æ¨¡æ€æ£€ç´¢ç³»ç»Ÿå®ç°**

**æ ¸å¿ƒç±»**ï¼š`CrossModalRetrieval`ï¼ˆä½äº `core/cross_modal_retrieval.py`ï¼‰

**ä¸»è¦åŠŸèƒ½**ï¼š
- `search()`: ç»Ÿä¸€çš„è·¨æ¨¡æ€æ£€ç´¢æ¥å£
- `text_to_image_search()`: æ–‡æœ¬åˆ°å›¾åƒæ£€ç´¢
- `image_to_text_search()`: å›¾åƒåˆ°æ–‡æœ¬æ£€ç´¢
- `get_image_text_pairs()`: è·å–å›¾åƒæ–‡æœ¬å¯¹

**ä½¿ç”¨æ–¹æ³•**ï¼š
```python
from core.cross_modal_retrieval import CrossModalRetrieval

# åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ
retrieval = CrossModalRetrieval()

# æ–‡æœ¬æ£€ç´¢
results = retrieval.search(query="èƒ¸éƒ¨Xå…‰æ£€æŸ¥", top_k=5)

# å›¾åƒæ£€ç´¢
results = retrieval.search(image_path="path/to/image.jpg", top_k=5)

# æ–‡æœ¬åˆ°å›¾åƒæ£€ç´¢
results = retrieval.text_to_image_search("è‚ºéƒ¨ç–¾ç—…", top_k=5)

# å›¾åƒåˆ°æ–‡æœ¬æ£€ç´¢
results = retrieval.image_to_text_search("path/to/image.jpg", top_k=5)
```
- æ£€ç´¢è¿‡ç¨‹ï¼š
  1. ç”¨æˆ·è¾“å…¥å›¾åƒ â†’ å‘é‡åŒ– â†’ åœ¨æ–‡æœ¬å‘é‡åº“ä¸­æœç´¢
  2. æ‰¾åˆ°ç›¸ä¼¼æ–‡æœ¬ â†’ ç›´æ¥è¿”å›æ–‡æœ¬å†…å®¹

3. **è·¨æ¨¡æ€æ£€ç´¢æµç¨‹**
```python
def search_by_image(self, image_path: str, top_k: int = 5) -> List[RetrievalResult]:
    """é€šè¿‡å›¾åƒæŸ¥è¯¢æ£€ç´¢ç›¸å…³å†…å®¹"""
    try:
        # 1. å¯¹è¾“å…¥å›¾åƒè¿›è¡Œå‘é‡åŒ–
        image_vector = self.image_embedder.embed_image(processed_image)
        
        # 2. åœ¨å›¾åƒå‘é‡æ•°æ®åº“ä¸­æœç´¢
        image_results = self.image_vector_db._collection.query(
            query_embeddings=[image_vector.tolist()],
            n_results=top_k
        )
        
        # 3. é€šè¿‡æ˜ å°„å…³ç³»è·å–å¯¹åº”æ–‡æœ¬
        results = []
        if image_results['ids'] and len(image_results['ids'][0]) > 0:
            for i, (doc_id, distance) in enumerate(zip(image_results['ids'][0], image_results['distances'][0])):
                # ä»doc_idä¸­æå–ç´¢å¼•
                index = int(doc_id.split('_')[-1])
                
                # é€šè¿‡æ˜ å°„å…³ç³»è·å–æ–‡æœ¬
                if str(index) in self.image_text_mapping:
                    mapping_info = self.image_text_mapping[str(index)]
                    result = RetrievalResult(
                        content=mapping_info['text'],
                        score=1.0 - distance,
                        metadata=mapping_info['metadata']
                    )
                    results.append(result)
        
        return results
    except Exception as e:
        logger.error(f"å›¾åƒæ£€ç´¢å¤±è´¥: {e}")
        return []
```

---

## ğŸ“ ç›®å½•ç»“æ„è¯¦è§£

### æ„å»ºçŸ¥è¯†åº“æ¨¡å— (`codes/ai_models/embedding_models/`)

```
embedding_models/
â”œâ”€â”€ core/                           # æ ¸å¿ƒåŠŸèƒ½æ¨¡å—
â”‚   â”œâ”€â”€ vectorization_service.py    # ç»Ÿä¸€å‘é‡åŒ–æœåŠ¡ â­
â”‚   â”œâ”€â”€ medical_knowledge_manager.py # åŒ»ç–—çŸ¥è¯†ç®¡ç†å™¨
â”‚   â”œâ”€â”€ data_analyzer.py            # æ•°æ®åˆ†æå™¨
â”‚   â”œâ”€â”€ build_vector_database.py    # å‘é‡æ•°æ®åº“æ„å»º
â”‚   â”œâ”€â”€ image_vectorization.py      # å›¾åƒå‘é‡åŒ–
â”‚   â”œâ”€â”€ cross_modal_retrieval.py # è·¨æ¨¡æ€æ£€ç´¢ â­
â”‚   â”œâ”€â”€ config.json                 # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ offline_test.py             # ç¦»çº¿æµ‹è¯•
â”œâ”€â”€ processors/                     # æ•°æ®å¤„ç†å™¨
â”‚   â”œâ”€â”€ document_chunker.py         # æ–‡æ¡£åˆ‡åˆ†å™¨ â­ æ–°å¢
â”‚   â”œâ”€â”€ text_preprocessing.py       # æ–‡æœ¬é¢„å¤„ç†
â”‚   â”œâ”€â”€ image_text_preprocessing.py # å›¾åƒæ–‡æœ¬è”åˆå¤„ç†
â”‚   â””â”€â”€ data_pipeline.py           # æ•°æ®å¤„ç†ç®¡é“
â”œâ”€â”€ models/                         # æ¨¡å‹ç›¸å…³
â”‚   â”œâ”€â”€ image_embedder.py          # å›¾åƒåµŒå…¥å™¨
â”‚   â””â”€â”€ pretrained/                # é¢„è®­ç»ƒæ¨¡å‹
â”œâ”€â”€ config/                         # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ unified_config.json        # ç»Ÿä¸€é…ç½®
â”‚   â””â”€â”€ medical_knowledge_config.json # åŒ»ç–—çŸ¥è¯†é…ç½®
â”œâ”€â”€ rag_system_test.py             # RAGç³»ç»Ÿæµ‹è¯• â­ æ–°å¢
â”œâ”€â”€ README_RAG_SYSTEM.md           # ç³»ç»Ÿæ¶æ„æ–‡æ¡£ â­ æ–°å¢
â””â”€â”€ README.md                      # æœ¬æ–‡æ¡£
```

### æ£€ç´¢æœåŠ¡æ¨¡å— (`codes/services/knowledge_retrieval_service/`)

```
knowledge_retrieval_service/
â”œâ”€â”€ core/                          # æ ¸å¿ƒæœåŠ¡æ¨¡å—
â”‚   â”œâ”€â”€ vector_service.py          # å‘é‡åŒ–æœåŠ¡ï¼ˆå·²ä¼˜åŒ–ï¼‰
â”‚   â”œâ”€â”€ retrieval_service.py       # æ£€ç´¢æœåŠ¡
â”‚   â”œâ”€â”€ llm_service.py            # å¤§è¯­è¨€æ¨¡å‹æœåŠ¡
â”‚   â”œâ”€â”€ rag_pipeline.py           # RAGå®Œæ•´æµç¨‹
â”‚   â””â”€â”€ config_manager.py         # é…ç½®ç®¡ç†å™¨
â”œâ”€â”€ api/                           # APIæ¥å£
â”‚   â”œâ”€â”€ rag_api.py                # FastAPIæ¥å£
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ rag_config.json       # é…ç½®æ–‡ä»¶
â”œâ”€â”€ start_rag_service.py          # å¯åŠ¨è„šæœ¬
â”œâ”€â”€ test_rag_service.py           # æµ‹è¯•è„šæœ¬
â””â”€â”€ README.md                     # æ¨¡å—æ–‡æ¡£
```

---

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½å®ç°

### 1. ç»Ÿä¸€å‘é‡åŒ–æœåŠ¡

**å®ç°ä½ç½®**ï¼š`core/vectorization_service.py`

**æœåŠ¡ç‰¹æ€§**ï¼š
- æ–‡æœ¬å‘é‡åŒ–
- å›¾åƒå‘é‡åŒ–
- å¤šæ¨¡æ€å¤„ç†
- æ‰¹é‡å¤„ç†ä¼˜åŒ–

```python
# ä½¿ç”¨ç¤ºä¾‹
from core.vectorization_service import VectorizationService

# åˆå§‹åŒ–å‘é‡åŒ–æœåŠ¡
service = VectorizationService()

# æ–‡æœ¬å‘é‡åŒ–
text_vectors = service.process_texts(texts)

# å›¾åƒå‘é‡åŒ–
image_vectors = service.process_images(image_paths)

# å¤šæ¨¡æ€å¤„ç†
result = service.process_multimodal(texts, image_paths)
```

### 2. è·¨æ¨¡æ€æ£€ç´¢åŠŸèƒ½ â­

**å®ç°ä½ç½®**ï¼š`core/cross_modal_retrieval.py`

**åŠŸèƒ½ç‰¹æ€§**ï¼š
- æ–‡æœ¬åˆ°æ–‡æœ¬æ£€ç´¢
- å›¾åƒåˆ°æ–‡æœ¬æ£€ç´¢
- æ··åˆæ£€ç´¢ï¼ˆæ–‡æœ¬+å›¾åƒï¼‰

```python
# ä½¿ç”¨ç¤ºä¾‹
from core.simple_cross_modal_retrieval import SimpleCrossModalRetrieval

# åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ
retrieval_system = SimpleCrossModalRetrieval()

# æ–‡æœ¬æ£€ç´¢
text_results = retrieval_system.search_by_text("å† å¿ƒç—…ç—‡çŠ¶", top_k=5)

# å›¾åƒåˆ°æ–‡æœ¬æ£€ç´¢
image_results = retrieval_system.search_by_image("path/to/image.jpg", top_k=5)

# æ··åˆæ£€ç´¢
mixed_results = retrieval_system.search_by_text_with_image(
    "å¿ƒè„ç–¾ç—…", "path/to/image.jpg", top_k=5
)
```

### 3. æ–‡æ¡£åˆ‡åˆ†åŠŸèƒ½ â­

**å®ç°ä½ç½®**ï¼š`processors/document_chunker.py`

**åˆ‡åˆ†ç­–ç•¥**ï¼š
- åŒ»ç–—ç»“æ„åŒ–åˆ‡åˆ†ï¼šè¯†åˆ«åŒ»ç–—æ–‡æ¡£ç« èŠ‚
- å¥å­è¾¹ç•Œåˆ‡åˆ†ï¼šä¿æŒå¥å­å®Œæ•´æ€§
- æ®µè½è¾¹ç•Œåˆ‡åˆ†ï¼šä¿æŒæ®µè½å®Œæ•´æ€§
- å›ºå®šå¤§å°åˆ‡åˆ†ï¼šé€‚åˆæ‰¹é‡å¤„ç†

```python
# ä½¿ç”¨ç¤ºä¾‹
from processors.document_chunker import create_medical_chunker

# åˆ›å»ºåŒ»ç–—æ–‡æ¡£åˆ‡åˆ†å™¨
chunker = create_medical_chunker()

# åˆ‡åˆ†æ–‡æ¡£
chunks = chunker.chunk_document(medical_text, metadata)

# æ‰¹é‡å¤„ç†æ–‡ä»¶
results = chunker.batch_chunk_files(input_dir, output_dir)
```

---

## ğŸ“Š æ•°æ®å­˜å‚¨ç»“æ„

### æ•°æ®ç›®å½•ç»“æ„

```
datas/medical_knowledge/
â”œâ”€â”€ text_data/                     # æ–‡æœ¬æ•°æ®
â”‚   â”œâ”€â”€ raw/                      # åŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ processed/                # å¤„ç†åæ•°æ®
â”‚   â””â”€â”€ embeddings/               # å‘é‡æ•°æ®
â”œâ”€â”€ image_text_data/              # å›¾åƒæ–‡æœ¬æ•°æ®
â”‚   â”œâ”€â”€ raw/                      # åŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ processed/                # å¤„ç†åæ•°æ®
â”‚   â””â”€â”€ embeddings/               # å‘é‡æ•°æ®
â”œâ”€â”€ voice_data/                   # è¯­éŸ³æ•°æ®
â”‚   â”œâ”€â”€ raw/                      # åŸå§‹æ•°æ®
â”‚   â”œâ”€â”€ processed/                # å¤„ç†åæ•°æ®
â”‚   â””â”€â”€ embeddings/               # å‘é‡æ•°æ®
â””â”€â”€ vector_databases/             # å‘é‡æ•°æ®åº“
    â”œâ”€â”€ text/                     # æ–‡æœ¬å‘é‡æ•°æ®åº“
    â”œâ”€â”€ image/                    # å›¾åƒå‘é‡æ•°æ®åº“
    â”œâ”€â”€ voice/                    # è¯­éŸ³å‘é‡æ•°æ®åº“
    â””â”€â”€ multimodal/               # å¤šæ¨¡æ€å‘é‡æ•°æ®åº“
```

### é…ç½®ç®¡ç†

**ç»Ÿä¸€é…ç½®æ–‡ä»¶**ï¼š`config/unified_config.json`

```json
{
  "models": {
    "text_embedding": {
      "model_name": "text2vec-base-chinese",
      "model_path": "../llm_models/text2vec-base-chinese",
      "max_length": 512,
      "batch_size": 32
    },
    "image_embedding": {
      "model_name": "clip-vit-base-patch32",
      "model_path": "models/pretrained/clip-vit-base-patch32",
      "image_size": 224,
      "batch_size": 16
    }
  },
  "data": {
    "base_dir": "/path/to/medical_knowledge",
    "text_data": {
      "raw_dir": "text_data/raw",
      "processed_dir": "text_data/processed",
      "embeddings_dir": "text_data/embeddings",
      "vector_db_dir": "vector_databases/text"
    }
  }
}
```

---

## ğŸš€ éƒ¨ç½²æŒ‡å—

### ç¯å¢ƒè¦æ±‚

**Pythonç¯å¢ƒ**ï¼š
- Python 3.8+
- æ¨èä½¿ç”¨condaç¯å¢ƒ

**ç³»ç»Ÿè¦æ±‚**ï¼š
- å†…å­˜ï¼šè‡³å°‘8GB RAM
- å­˜å‚¨ï¼šè‡³å°‘10GBå¯ç”¨ç©ºé—´
- CPUï¼šå¤šæ ¸å¤„ç†å™¨æ¨è

### ä¾èµ–å®‰è£…

```bash
# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install -r requirements.txt

# æˆ–è€…ä½¿ç”¨conda
conda install numpy pandas pillow scikit-learn
pip install torch transformers sentence-transformers
pip install chromadb faiss-cpu
pip install jieba pypinyin
```

### éƒ¨ç½²æ­¥éª¤

#### æ­¥éª¤1ï¼šç¯å¢ƒé…ç½®

```bash
# 1. å…‹éš†æˆ–å¤åˆ¶é¡¹ç›®
cd /path/to/zhi_zhen_tong_system

# 2. è¿›å…¥å‘é‡åŒ–æ¨¡å—ç›®å½•
cd codes/ai_models/embedding_models

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

#### æ­¥éª¤2ï¼šæ•°æ®æ£€æŸ¥

```bash
# æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å®Œæ•´
python run_vectorization.py --mode check
```

#### æ­¥éª¤3ï¼šæ„å»ºå‘é‡æ•°æ®åº“

```bash
# å®Œæ•´æ„å»ºï¼ˆæ¨èï¼‰
python run_vectorization.py --mode all

# æˆ–è€…åˆ†æ­¥æ„å»º
python run_vectorization.py --mode preprocess  # æ•°æ®é¢„å¤„ç†
python run_vectorization.py --mode multimodal  # å¤šæ¨¡æ€å‘é‡åŒ–
```

#### æ­¥éª¤4ï¼šæµ‹è¯•ç³»ç»Ÿ

```bash
# æµ‹è¯•æ£€ç´¢åŠŸèƒ½
python run_vectorization.py --mode test

# è¯¦ç»†æµ‹è¯•
python test_unified_retrieval.py
```

### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

#### æ–¹æ¡ˆä¸€ï¼šä¸€é”®å¯åŠ¨ï¼ˆæ¨èç”¨äºæµ‹è¯•ç¯å¢ƒï¼‰

```bash
# 1. å¯åŠ¨Docker Desktopï¼ˆå¦‚æœæœªå¯åŠ¨ï¼‰
# 2. ä¸€é”®å¯åŠ¨æ‰€æœ‰æœåŠ¡
cd codes
./start-all.sh
```

#### æ–¹æ¡ˆäºŒï¼šDocker Composeéƒ¨ç½²ï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰

```bash
# 1. å¯åŠ¨åŸºç¡€æœåŠ¡
cd codes/backend
docker-compose up -d postgres redis rabbitmq

# 2. å¯åŠ¨åç«¯æœåŠ¡
cd ../backend
./start-dev.sh

# 3. å¯åŠ¨å‰ç«¯æœåŠ¡
cd ../frontend
npm run build
npm run preview
```

#### æ–¹æ¡ˆä¸‰ï¼šå®Œå…¨å®¹å™¨åŒ–éƒ¨ç½²

```bash
# ä½¿ç”¨å®Œæ•´çš„Docker Composeé…ç½®
cd codes
docker-compose up -d
```

---

## ğŸ“‹ éƒ¨ç½²æ£€æŸ¥æ¸…å•

### åŸºç¡€æ£€æŸ¥
- [ ] Pythonç¯å¢ƒæ­£ç¡®å®‰è£…
- [ ] æ‰€æœ‰ä¾èµ–åŒ…å·²å®‰è£…
- [ ] æ•°æ®æ–‡ä»¶å®Œæ•´
- [ ] é…ç½®æ–‡ä»¶æ­£ç¡®

### åŠŸèƒ½æ£€æŸ¥
- [ ] æ–‡æœ¬æ£€ç´¢æ­£å¸¸å·¥ä½œ
- [ ] å›¾åƒæ£€ç´¢æ­£å¸¸å·¥ä½œ
- [ ] å‘é‡æ•°æ®åº“æ„å»ºæˆåŠŸ
- [ ] ç»Ÿä¸€æ£€ç´¢æ¥å£å¯ç”¨
- [ ] é”™è¯¯å¤„ç†æœºåˆ¶æ­£å¸¸

### æ€§èƒ½æ£€æŸ¥
- [ ] æ£€ç´¢å“åº”æ—¶é—´åˆç†ï¼ˆ<2ç§’ï¼‰
- [ ] å†…å­˜ä½¿ç”¨æ­£å¸¸
- [ ] å¹¶å‘å¤„ç†èƒ½åŠ›

### ç”Ÿäº§ç¯å¢ƒæ£€æŸ¥
- [ ] DockeræœåŠ¡è¿è¡Œæ­£å¸¸
- [ ] æ•°æ®åº“è¿æ¥æ­£å¸¸
- [ ] ç›‘æ§å’Œæ—¥å¿—é…ç½®
- [ ] å¤‡ä»½å’Œæ¢å¤æœºåˆ¶

---

## ğŸ§ª æµ‹è¯•å’ŒéªŒè¯

### ç³»ç»Ÿæµ‹è¯•

**æµ‹è¯•è„šæœ¬**ï¼š`rag_system_test.py`

**æµ‹è¯•å†…å®¹**ï¼š
- æ–‡æ¡£åˆ‡åˆ†åŠŸèƒ½æµ‹è¯•
- çŸ¥è¯†åº“æ„å»ºåŠŸèƒ½æµ‹è¯•
- æ£€ç´¢ç”Ÿæˆæ¨¡å—åŠŸèƒ½æµ‹è¯•
- è·¨æ¨¡æ€æ£€ç´¢åŠŸèƒ½æµ‹è¯•
- ç³»ç»Ÿé›†æˆæµ‹è¯•

```bash
# è¿è¡Œå®Œæ•´ç³»ç»Ÿæµ‹è¯•
cd codes/ai_models/embedding_models
python rag_system_test.py
```

### æ¨¡å—æµ‹è¯•

```bash
# æµ‹è¯•æ–‡æ¡£åˆ‡åˆ†åŠŸèƒ½
python processors/document_chunker.py

# æµ‹è¯•è·¨æ¨¡æ€æ£€ç´¢
python core/offline_test.py

# æµ‹è¯•å‘é‡åŒ–æœåŠ¡
python core/vectorization_service.py
```

### æµ‹è¯•æŠ¥å‘Š

æµ‹è¯•å®Œæˆåä¼šç”Ÿæˆè¯¦ç»†çš„æµ‹è¯•æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
- åŠŸèƒ½æµ‹è¯•ç»“æœ
- æ€§èƒ½æŒ‡æ ‡
- æ”¹è¿›å»ºè®®
- ç³»ç»ŸçŠ¶æ€

---

## ğŸ” ç³»ç»Ÿä¼˜åŒ–

### 1. é‡å¤åŠŸèƒ½æ¶ˆé™¤

**ä¼˜åŒ–å‰é—®é¢˜**ï¼š
- æ„å»ºçŸ¥è¯†åº“æ¨¡å—å’Œæ£€ç´¢ç”Ÿæˆæ¨¡å—éƒ½å®ç°äº†å‘é‡åŒ–åŠŸèƒ½
- é…ç½®ä¸ä¸€è‡´ï¼Œæ¨¡å‹ç»´åº¦ä¸åŒ¹é…

**ä¼˜åŒ–åæ–¹æ¡ˆ**ï¼š
- æ£€ç´¢ç”Ÿæˆæ¨¡å—è°ƒç”¨æ„å»ºçŸ¥è¯†åº“æ¨¡å—çš„å‘é‡åŒ–æœåŠ¡
- ç»Ÿä¸€é…ç½®ç®¡ç†ï¼Œç¡®ä¿æ¨¡å‹ä¸€è‡´æ€§
- ä¿ç•™å¤‡ç”¨æ–¹æ¡ˆï¼Œç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§

### 2. æ€§èƒ½ä¼˜åŒ–

- æ‰¹é‡å¤„ç†ä¼˜åŒ–
- å‘é‡æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–
- ç¼“å­˜æœºåˆ¶å®ç°
- å¼‚æ­¥å¤„ç†æ”¯æŒ

### 3. æ‰©å±•æ€§è®¾è®¡

- æ¨¡å—åŒ–æ¶æ„
- æ’ä»¶å¼æ‰©å±•
- é…ç½®é©±åŠ¨
- å¤šæ¨¡æ€æ”¯æŒ

---

## ğŸ“ˆ ç³»ç»Ÿç›‘æ§

### æ€§èƒ½æŒ‡æ ‡

- å‘é‡åŒ–å¤„ç†é€Ÿåº¦
- æ£€ç´¢å“åº”æ—¶é—´
- ç”Ÿæˆè´¨é‡è¯„ä¼°
- ç³»ç»Ÿèµ„æºä½¿ç”¨

### æ—¥å¿—è®°å½•

- æ“ä½œæ—¥å¿—
- é”™è¯¯æ—¥å¿—
- æ€§èƒ½æ—¥å¿—
- å®¡è®¡æ—¥å¿—

### ç›‘æ§è„šæœ¬

```bash
# æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
./status.sh

# æŸ¥çœ‹ç³»ç»Ÿæ—¥å¿—
tail -f backend/logs/backend.log

# ç›‘æ§ç³»ç»Ÿèµ„æº
top -p $(pgrep -f "python.*run_vectorization")
```

---

## âš ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**1. æ¨¡å‹ä¸‹è½½å¤±è´¥**
```bash
# è§£å†³æ–¹æ¡ˆï¼šä½¿ç”¨ä»£ç†æˆ–æœ¬åœ°æ¨¡å‹
export HF_ENDPOINT=https://hf-mirror.com
```

**2. å†…å­˜ä¸è¶³**
```bash
# è§£å†³æ–¹æ¡ˆï¼šå‡å°‘æ‰¹å¤„ç†å¤§å°
# ä¿®æ”¹config.jsonä¸­çš„BATCH_SIZE
```

**3. å›¾åƒå¤„ç†å¤±è´¥**
```bash
# è§£å†³æ–¹æ¡ˆï¼šæ£€æŸ¥å›¾åƒæ–‡ä»¶æ ¼å¼
# ç¡®ä¿æ”¯æŒPNGã€JPGã€JPEGæ ¼å¼
```

**4. DockeræœåŠ¡æœªè¿è¡Œ**
```bash
# è§£å†³æ–¹æ¡ˆï¼šå¯åŠ¨Docker Desktop
# æ£€æŸ¥DockeræœåŠ¡çŠ¶æ€
docker --version
```

### é”™è¯¯ä»£ç 

| é”™è¯¯ä»£ç  | æè¿° | è§£å†³æ–¹æ¡ˆ |
|---------|------|----------|
| E001 | æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨ | æ£€æŸ¥æ•°æ®ç›®å½•ç»“æ„ |
| E002 | æ¨¡å‹åŠ è½½å¤±è´¥ | æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæ¨¡å‹è·¯å¾„ |
| E003 | å†…å­˜ä¸è¶³ | å‡å°‘æ‰¹å¤„ç†å¤§å° |
| E004 | å‘é‡æ•°æ®åº“é”™è¯¯ | é‡æ–°æ„å»ºå‘é‡æ•°æ®åº“ |
| E005 | DockeræœåŠ¡æœªè¿è¡Œ | å¯åŠ¨Docker Desktop |

---

## ğŸ”® æœªæ¥è§„åˆ’

### 1. åŠŸèƒ½æ‰©å±•

- æ”¯æŒæ›´å¤šæ–‡æ¡£æ ¼å¼
- å®ç°å®æ—¶å­¦ä¹ 
- æ·»åŠ å¤šè¯­è¨€æ”¯æŒ
- å¢å¼ºå›¾åƒç†è§£èƒ½åŠ›

### 2. æ€§èƒ½æå‡

- GPUåŠ é€Ÿä¼˜åŒ–
- åˆ†å¸ƒå¼å¤„ç†
- æ¨¡å‹å‹ç¼©
- è¾¹ç¼˜è®¡ç®—æ”¯æŒ

### 3. ç”¨æˆ·ä½“éªŒ

- æ™ºèƒ½æ¨è
- ä¸ªæ€§åŒ–å®šåˆ¶
- å¤šè½®å¯¹è¯
- å¯è§†åŒ–ç•Œé¢

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### æ—¥å¿—æ”¶é›†

```bash
# æ”¶é›†ç³»ç»Ÿæ—¥å¿—
python run_vectorization.py --mode test > test.log 2>&1
```

### æ€§èƒ½ç›‘æ§

```bash
# ç›‘æ§ç³»ç»Ÿèµ„æº
top -p $(pgrep -f "python.*run_vectorization")
```

### å¿«é€Ÿå¯åŠ¨å‘½ä»¤

```bash
# ä¸€é”®å¯åŠ¨æ‰€æœ‰æœåŠ¡
./start-all.sh

# å•ç‹¬å¯åŠ¨åç«¯
cd backend && ./start-dev.sh

# æŸ¥çœ‹åç«¯æ—¥å¿—
tail -f backend/logs/backend.log

# æŸ¥çœ‹å‰ç«¯æ—¥å¿—
tail -f backend/logs/frontend.log

# æŸ¥çœ‹Dockeræ—¥å¿—
cd backend && docker compose logs -f

# æ£€æŸ¥APIå¥åº·
curl http://localhost:8000/health
```

---

## ğŸ‰ æ€»ç»“

### ç³»ç»Ÿä¼˜åŠ¿

âœ… **ç»Ÿä¸€æ¶æ„**ï¼šè§£å†³äº†å¤šæ•°æ®åº“å†—ä½™é—®é¢˜  
âœ… **æ™ºèƒ½æ£€ç´¢**ï¼šæ”¯æŒæ–‡æœ¬ã€å›¾åƒã€æ··åˆæŸ¥è¯¢  
âœ… **å®¹é”™æœºåˆ¶**ï¼šç½‘ç»œé—®é¢˜è‡ªåŠ¨å¤„ç†  
âœ… **é«˜æ•ˆå­˜å‚¨**ï¼šå•ä¸€æ•°æ®åº“æ¶æ„  
âœ… **å®Œæ•´æµ‹è¯•**ï¼šæ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½éªŒè¯é€šè¿‡  
âœ… **ç”Ÿäº§å°±ç»ª**ï¼šå®Œæ•´çš„éƒ¨ç½²é…ç½®å’Œç›‘æ§ä½“ç³»

### æ ¸å¿ƒæˆå°±

1. **å¤šæ¨¡æ€æ£€ç´¢**ï¼šå®ç°äº†å›¾åƒåˆ°æ–‡æœ¬çš„è·¨æ¨¡æ€æ£€ç´¢
2. **ç»Ÿä¸€å‘é‡åŒ–**ï¼šæ¶ˆé™¤äº†é‡å¤åŠŸèƒ½ï¼Œæé«˜ç³»ç»Ÿä¸€è‡´æ€§
3. **æ™ºèƒ½åˆ‡åˆ†**ï¼šæ”¯æŒåŒ»ç–—æ–‡æ¡£çš„ç»“æ„åŒ–åˆ‡åˆ†
4. **ç”Ÿäº§éƒ¨ç½²**ï¼šå®Œæ•´çš„DockeråŒ–éƒ¨ç½²æ–¹æ¡ˆ
5. **ç›‘æ§ä½“ç³»**ï¼šå…¨é¢çš„ç³»ç»Ÿç›‘æ§å’Œæ•…éšœæ’é™¤

### éƒ¨ç½²çŠ¶æ€

**æ™ºè¯Šé€šå¤šæ¨¡æ€å‘é‡åŒ–ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥éƒ¨ç½²ï¼**

- **éƒ¨ç½²çŠ¶æ€**ï¼šğŸŸ¢ å¯ä»¥éƒ¨ç½²
- **ç³»ç»Ÿç¨³å®šæ€§**ï¼šğŸŸ¢ é«˜
- **åŠŸèƒ½å®Œæ•´æ€§**ï¼šğŸŸ¢ å®Œæ•´
- **æµ‹è¯•è¦†ç›–åº¦**ï¼šğŸŸ¢ å…¨é¢

---

**ç‰ˆæœ¬**ï¼šv2.0.0  
**æ›´æ–°æ—¶é—´**ï¼š2025å¹´9æœˆ  
**ç»´æŠ¤å›¢é˜Ÿ**ï¼šæ™ºè¯Šé€šå¼€å‘å›¢é˜Ÿ  
**æ–‡æ¡£çŠ¶æ€**ï¼šå®Œæ•´ã€æ¸…æ™°ã€åˆç†
