#!/usr/bin/env conda run -n nlp python
"""
æ£€æŸ¥é¡¹ç›®ä¸­çš„æ¨¡å‹ä½¿ç”¨æƒ…å†µï¼Œæ’é™¤ç¬¬ä¸‰æ–¹åº“
"""

import os
import re
import json
from pathlib import Path
from typing import List, Dict, Tuple

class ProjectModelChecker:
    """é¡¹ç›®æ¨¡å‹æ£€æŸ¥å™¨"""
    
    def __init__(self, project_root: str = None):
        """
        åˆå§‹åŒ–æ£€æŸ¥å™¨
        
        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•
        """
        if project_root is None:
            # è·å–é¡¹ç›®æ ¹ç›®å½•
            self.project_root = Path(__file__).parent.parent.parent.parent
        else:
            self.project_root = Path(project_root)
        
        # éœ€è¦æ’é™¤çš„ç›®å½•
        self.exclude_dirs = {
            "venv", "__pycache__", ".git", "node_modules", 
            ".venv", "site-packages", ".pytest_cache"
        }
        
        # éœ€è¦æ£€æŸ¥çš„ç›®å½•
        self.check_dirs = {
            "codes/backend/app",
            "codes/services", 
            "codes/ai_models",
            "codes/frontend/src"
        }
        
        # æ¨¡å‹ç›¸å…³çš„å…³é”®è¯å’Œæ¨¡å¼
        self.model_patterns = {
            "llm_models": [
                r"Qwen2-0.5B-Medical-MLX",
                r"microsoft/DialoGPT",
                r"AutoModelForCausalLM",
                r"AutoTokenizer"
            ],
            "embedding_models": [
                r"text2vec-base-chinese",
                r"shibing624/text2vec-base-chinese",
                r"SentenceTransformer",
                r"clip-ViT-B-32"
            ]
        }
        
        # æœ¬åœ°æ¨¡å‹è·¯å¾„
        self.local_model_paths = {
            "Qwen2-0.5B-Medical-MLX": str(self.project_root / "codes/ai_models/llm_models/Qwen2-0.5B-Medical-MLX"),
            "text2vec-base-chinese": str(self.project_root / "codes/ai_models/llm_models/text2vec-base-chinese")
        }
    
    def should_check_file(self, file_path: Path) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥æ£€æŸ¥è¯¥æ–‡ä»¶
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦åº”è¯¥æ£€æŸ¥
        """
        # æ£€æŸ¥æ˜¯å¦åœ¨æ’é™¤ç›®å½•ä¸­
        for part in file_path.parts:
            if part in self.exclude_dirs:
                return False
        
        # æ£€æŸ¥æ˜¯å¦åœ¨éœ€è¦æ£€æŸ¥çš„ç›®å½•ä¸­
        relative_path = file_path.relative_to(self.project_root)
        for check_dir in self.check_dirs:
            if str(relative_path).startswith(check_dir):
                return True
        
        return False
    
    def check_file(self, file_path: Path) -> Dict:
        """
        æ£€æŸ¥å•ä¸ªæ–‡ä»¶ä¸­çš„æ¨¡å‹ä½¿ç”¨æƒ…å†µ
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ£€æŸ¥ç»“æœ
        """
        result = {
            "file_path": str(file_path.relative_to(self.project_root)),
            "model_usage": [],
            "needs_update": False,
            "is_local": False
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            for line_num, line in enumerate(lines, 1):
                # æ£€æŸ¥å„ç§æ¨¡å‹æ¨¡å¼
                for model_type, patterns in self.model_patterns.items():
                    for pattern in patterns:
                        if re.search(pattern, line):
                            usage_info = {
                                "line": line_num,
                                "content": line.strip(),
                                "pattern": pattern,
                                "model_type": model_type
                            }
                            
                            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨æœ¬åœ°è·¯å¾„
                            is_local = any(local_path in line for local_path in self.local_model_paths.values())
                            usage_info["is_local"] = is_local
                            
                            if not is_local and "microsoft/DialoGPT" in line:
                                result["needs_update"] = True
                            
                            result["model_usage"].append(usage_info)
            
            # æ£€æŸ¥æ˜¯å¦ä¸»è¦ä½¿ç”¨æœ¬åœ°æ¨¡å‹
            local_count = sum(1 for usage in result["model_usage"] if usage["is_local"])
            total_count = len(result["model_usage"])
            result["is_local"] = local_count > 0 and local_count >= total_count * 0.5
            
        except Exception as e:
            result["error"] = str(e)
        
        return result
    
    def check_all_files(self) -> Dict[str, List[Dict]]:
        """
        æ£€æŸ¥æ‰€æœ‰ç›¸å…³æ–‡ä»¶
        
        Returns:
            æ£€æŸ¥ç»“æœ
        """
        results = {
            "python_files": [],
            "config_files": [],
            "script_files": [],
            "documentation": []
        }
        
        # éå†é¡¹ç›®æ–‡ä»¶
        for file_path in self.project_root.rglob("*"):
            if not file_path.is_file():
                continue
            
            if not self.should_check_file(file_path):
                continue
            
            # åªæ£€æŸ¥ç‰¹å®šç±»å‹çš„æ–‡ä»¶
            if file_path.suffix not in ['.py', '.json', '.sh', '.md']:
                continue
            
            result = self.check_file(file_path)
            
            # åªä¿ç•™æœ‰æ¨¡å‹ä½¿ç”¨çš„æ–‡ä»¶
            if result["model_usage"]:
                file_type = self._get_file_type(file_path)
                results[file_type].append(result)
        
        return results
    
    def _get_file_type(self, file_path: Path) -> str:
        """
        è·å–æ–‡ä»¶ç±»å‹
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ–‡ä»¶ç±»å‹
        """
        if file_path.suffix == '.py':
            return "python_files"
        elif file_path.suffix == '.json':
            return "config_files"
        elif file_path.suffix == '.sh':
            return "script_files"
        else:
            return "documentation"
    
    def generate_report(self) -> str:
        """
        ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š
        
        Returns:
            æŠ¥å‘Šå†…å®¹
        """
        results = self.check_all_files()
        
        report = """# æ™ºè¯Šé€šç³»ç»Ÿé¡¹ç›®æ¨¡å‹ä½¿ç”¨æ£€æŸ¥æŠ¥å‘Š

## ğŸ“‹ æ£€æŸ¥æ¦‚è¿°

æœ¬æŠ¥å‘Šæ£€æŸ¥äº†æ™ºè¯Šé€šç³»ç»Ÿé¡¹ç›®ä¸­æ‰€æœ‰æ¨¡å‹ä½¿ç”¨çš„åœ°æ–¹ï¼Œç¡®ä¿ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ã€‚

## ğŸ” æ£€æŸ¥ç»“æœ

"""
        
        total_files = sum(len(files) for files in results.values())
        report += f"**æ€»è®¡æ£€æŸ¥æ–‡ä»¶æ•°**: {total_files}\n\n"
        
        # ç»Ÿè®¡ä¿¡æ¯
        needs_update_count = 0
        local_count = 0
        
        for file_type, files in results.items():
            if not files:
                continue
                
            report += f"### {file_type.replace('_', ' ').title()}\n\n"
            
            for file_info in files:
                if file_info.get("needs_update"):
                    needs_update_count += 1
                if file_info.get("is_local"):
                    local_count += 1
                
                status = "âœ… æœ¬åœ°æ¨¡å‹" if file_info.get("is_local") else "âš ï¸ éœ€è¦æ›´æ–°"
                if file_info.get("needs_update"):
                    status = "âŒ éœ€è¦æ›´æ–°"
                
                report += f"#### {file_info['file_path']}\n"
                report += f"**çŠ¶æ€**: {status}\n\n"
                
                for usage in file_info['model_usage']:
                    local_indicator = "ğŸ " if usage["is_local"] else "ğŸŒ"
                    report += f"- {local_indicator} **ç¬¬{usage['line']}è¡Œ**: `{usage['content']}`\n"
                    report += f"  - ç±»å‹: {usage['model_type']}\n"
                    report += f"  - æ¨¡å¼: `{usage['pattern']}`\n"
                
                if file_info.get("error"):
                    report += f"âš ï¸ **é”™è¯¯**: {file_info['error']}\n"
                
                report += "\n"
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        report += f"""## ğŸ“Š ç»Ÿè®¡ä¿¡æ¯

- **æ€»æ–‡ä»¶æ•°**: {total_files}
- **ä½¿ç”¨æœ¬åœ°æ¨¡å‹**: {local_count}
- **éœ€è¦æ›´æ–°**: {needs_update_count}
- **æœ¬åœ°åŒ–ç‡**: {(local_count/total_files*100):.1f}% (å¦‚æœtotal_files > 0)

## ğŸ’¡ å»ºè®®

### 1. ä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹
- ç¡®ä¿æ‰€æœ‰é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹è·¯å¾„æŒ‡å‘æœ¬åœ°æ¨¡å‹
- é¿å…åœ¨è¿è¡Œæ—¶ä¸‹è½½æ¨¡å‹ï¼Œæé«˜å¯åŠ¨é€Ÿåº¦

### 2. ç»Ÿä¸€æ¨¡å‹ç®¡ç†
- ä½¿ç”¨ `model_manager.py` ç»Ÿä¸€ç®¡ç†æ¨¡å‹è·¯å¾„
- å®šæœŸè¿è¡Œæ¨¡å‹ç®¡ç†å™¨æ›´æ–°é…ç½®æ–‡ä»¶

### 3. æ£€æŸ¥æ¸…å•
- [ ] æ‰€æœ‰Pythonæ–‡ä»¶ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„
- [ ] é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹è·¯å¾„æ­£ç¡®
- [ ] å¯åŠ¨è„šæœ¬æ£€æŸ¥æœ¬åœ°æ¨¡å‹å­˜åœ¨æ€§
- [ ] æ–‡æ¡£ä¸­çš„æ¨¡å‹è·¯å¾„ä¿¡æ¯å‡†ç¡®

## ğŸ”§ ä¿®å¤å»ºè®®

å¦‚æœå‘ç°éœ€è¦æ›´æ–°çš„æ–‡ä»¶ï¼Œè¯·ï¼š

1. ä½¿ç”¨æ¨¡å‹ç®¡ç†å™¨è‡ªåŠ¨æ›´æ–°ï¼š
   ```python
   from model_manager import ModelManager
   manager = ModelManager()
   manager.update_config_files(use_local_models=True)
   ```

2. æ‰‹åŠ¨æ›´æ–°é…ç½®æ–‡ä»¶ä¸­çš„æ¨¡å‹è·¯å¾„

3. ç¡®ä¿æœ¬åœ°æ¨¡å‹æ–‡ä»¶å®Œæ•´ä¸”å¯è®¿é—®

---
**æ£€æŸ¥æ—¶é—´**: 2024å¹´9æœˆ11æ—¥  
**æ£€æŸ¥å·¥å…·**: ProjectModelChecker  
**çŠ¶æ€**: âœ… å®Œæˆ
"""
        
        return report
    
    def save_report(self, output_path: str = None) -> bool:
        """
        ä¿å­˜æ£€æŸ¥æŠ¥å‘Š
        
        Args:
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            æ˜¯å¦æˆåŠŸä¿å­˜
        """
        try:
            if output_path is None:
                output_path = self.project_root / "codes/ai_models/llm_models/é¡¹ç›®æ¨¡å‹ä½¿ç”¨æ£€æŸ¥æŠ¥å‘Š.md"
            
            report_content = self.generate_report()
            
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report_content)
            
            print(f"æ£€æŸ¥æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path}")
            return True
            
        except Exception as e:
            print(f"ä¿å­˜æ£€æŸ¥æŠ¥å‘Šå¤±è´¥: {e}")
            return False


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” æ™ºè¯Šé€šç³»ç»Ÿé¡¹ç›®æ¨¡å‹ä½¿ç”¨æ£€æŸ¥å™¨")
    print("=" * 50)
    
    # åˆ›å»ºæ£€æŸ¥å™¨
    checker = ProjectModelChecker()
    
    # ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
    print("æ­£åœ¨æ£€æŸ¥é¡¹ç›®æ¨¡å‹ä½¿ç”¨æƒ…å†µ...")
    if checker.save_report():
        print("âœ… æ£€æŸ¥æŠ¥å‘Šç”ŸæˆæˆåŠŸ")
    else:
        print("âŒ æ£€æŸ¥æŠ¥å‘Šç”Ÿæˆå¤±è´¥")
    
    print("\nğŸ‰ é¡¹ç›®æ¨¡å‹ä½¿ç”¨æ£€æŸ¥å®Œæˆï¼")


if __name__ == "__main__":
    main()
